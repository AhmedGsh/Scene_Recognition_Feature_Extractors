{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import timeit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = 'resnet50'\n",
    "\n",
    "model_file = '%s_places365.pth.tar' % arch\n",
    "if not os.access(model_file, os.W_OK):\n",
    "    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n",
    "    os.system('wget ' + weight_url)\n",
    "\n",
    "model = models.__dict__[arch](num_classes=365)\n",
    "checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=365, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                  [-1, 365]         747,885\n",
      "================================================================\n",
      "Total params: 24,255,917\n",
      "Trainable params: 24,255,917\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 92.53\n",
      "Estimated Total Size (MB): 379.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 10**(-4)\n",
    "workers = 0\n",
    "\n",
    "folder_path =r'C:\\Users\\duke\\Desktop\\CS6670_Final_Project\\places365standard_easyformat\\places365_standard'\n",
    "traindir = os.path.join(folder_path, 'train')\n",
    "valdir = os.path.join(folder_path, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(traindir, transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,])),\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True)\n",
    "\n",
    "# define loss function (criterion) and pptimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [0/1141]\tLoss 1.2866 (1.2866)\tPrec@1 37.500 (37.500)\tPrec@5 96.875 (96.875)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1/1141]\tLoss 1.0724 (1.1795)\tPrec@1 62.500 (50.000)\tPrec@5 93.750 (95.312)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [2/1141]\tLoss 1.3336 (1.2309)\tPrec@1 59.375 (53.125)\tPrec@5 90.625 (93.750)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [3/1141]\tLoss 0.7729 (1.1164)\tPrec@1 71.875 (57.812)\tPrec@5 96.875 (94.531)\n",
      "tensor(96.8750, device='cuda:0')\n",
      "Test: [4/1141]\tLoss 0.1638 (0.9259)\tPrec@1 96.875 (65.625)\tPrec@5 100.000 (95.625)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [5/1141]\tLoss 0.6992 (0.8881)\tPrec@1 84.375 (68.750)\tPrec@5 93.750 (95.312)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [6/1141]\tLoss 1.6563 (0.9978)\tPrec@1 46.875 (65.625)\tPrec@5 87.500 (94.196)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [7/1141]\tLoss 1.8938 (1.1098)\tPrec@1 50.000 (63.672)\tPrec@5 90.625 (93.750)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [8/1141]\tLoss 1.4724 (1.1501)\tPrec@1 50.000 (62.153)\tPrec@5 87.500 (93.056)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [9/1141]\tLoss 1.6999 (1.2051)\tPrec@1 43.750 (60.312)\tPrec@5 93.750 (93.125)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [10/1141]\tLoss 2.3689 (1.3109)\tPrec@1 31.250 (57.670)\tPrec@5 75.000 (91.477)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [11/1141]\tLoss 2.9429 (1.4469)\tPrec@1 34.375 (55.729)\tPrec@5 68.750 (89.583)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [12/1141]\tLoss 1.8769 (1.4800)\tPrec@1 40.625 (54.567)\tPrec@5 93.750 (89.904)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [13/1141]\tLoss 1.7869 (1.5019)\tPrec@1 46.875 (54.018)\tPrec@5 87.500 (89.732)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [14/1141]\tLoss 1.2321 (1.4839)\tPrec@1 59.375 (54.375)\tPrec@5 87.500 (89.583)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [15/1141]\tLoss 1.6845 (1.4964)\tPrec@1 53.125 (54.297)\tPrec@5 78.125 (88.867)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [16/1141]\tLoss 1.7764 (1.5129)\tPrec@1 68.750 (55.147)\tPrec@5 78.125 (88.235)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [17/1141]\tLoss 0.8179 (1.4743)\tPrec@1 75.000 (56.250)\tPrec@5 100.000 (88.889)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [18/1141]\tLoss 1.4765 (1.4744)\tPrec@1 65.625 (56.743)\tPrec@5 90.625 (88.980)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [19/1141]\tLoss 1.4565 (1.4735)\tPrec@1 65.625 (57.188)\tPrec@5 84.375 (88.750)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [20/1141]\tLoss 1.5553 (1.4774)\tPrec@1 62.500 (57.440)\tPrec@5 81.250 (88.393)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [21/1141]\tLoss 1.5019 (1.4785)\tPrec@1 65.625 (57.812)\tPrec@5 81.250 (88.068)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [22/1141]\tLoss 1.8548 (1.4949)\tPrec@1 53.125 (57.609)\tPrec@5 75.000 (87.500)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [23/1141]\tLoss 2.2779 (1.5275)\tPrec@1 46.875 (57.161)\tPrec@5 81.250 (87.240)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [24/1141]\tLoss 2.8573 (1.5807)\tPrec@1 28.125 (56.000)\tPrec@5 68.750 (86.500)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [25/1141]\tLoss 2.4110 (1.6126)\tPrec@1 34.375 (55.168)\tPrec@5 65.625 (85.697)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [26/1141]\tLoss 2.6097 (1.6496)\tPrec@1 28.125 (54.167)\tPrec@5 68.750 (85.069)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [27/1141]\tLoss 3.2738 (1.7076)\tPrec@1 28.125 (53.237)\tPrec@5 56.250 (84.040)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [28/1141]\tLoss 1.7400 (1.7087)\tPrec@1 62.500 (53.556)\tPrec@5 81.250 (83.944)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [29/1141]\tLoss 1.2063 (1.6919)\tPrec@1 62.500 (53.854)\tPrec@5 90.625 (84.167)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [30/1141]\tLoss 1.3511 (1.6810)\tPrec@1 53.125 (53.831)\tPrec@5 93.750 (84.476)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [31/1141]\tLoss 1.1999 (1.6659)\tPrec@1 53.125 (53.809)\tPrec@5 93.750 (84.766)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [32/1141]\tLoss 1.3046 (1.6550)\tPrec@1 62.500 (54.072)\tPrec@5 93.750 (85.038)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [33/1141]\tLoss 1.8528 (1.6608)\tPrec@1 53.125 (54.044)\tPrec@5 84.375 (85.018)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [34/1141]\tLoss 1.6771 (1.6613)\tPrec@1 56.250 (54.107)\tPrec@5 87.500 (85.089)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [35/1141]\tLoss 1.6234 (1.6602)\tPrec@1 62.500 (54.340)\tPrec@5 87.500 (85.156)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [36/1141]\tLoss 2.1975 (1.6747)\tPrec@1 46.875 (54.139)\tPrec@5 84.375 (85.135)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [37/1141]\tLoss 2.1141 (1.6863)\tPrec@1 46.875 (53.947)\tPrec@5 87.500 (85.197)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [38/1141]\tLoss 2.0913 (1.6967)\tPrec@1 28.125 (53.285)\tPrec@5 93.750 (85.417)\n",
      "tensor(12.5000, device='cuda:0')\n",
      "Test: [39/1141]\tLoss 3.0596 (1.7307)\tPrec@1 12.500 (52.266)\tPrec@5 65.625 (84.922)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [40/1141]\tLoss 2.3873 (1.7468)\tPrec@1 25.000 (51.601)\tPrec@5 81.250 (84.832)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [41/1141]\tLoss 1.4474 (1.7396)\tPrec@1 53.125 (51.637)\tPrec@5 93.750 (85.045)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [42/1141]\tLoss 1.4592 (1.7331)\tPrec@1 59.375 (51.817)\tPrec@5 84.375 (85.029)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [43/1141]\tLoss 1.4279 (1.7262)\tPrec@1 56.250 (51.918)\tPrec@5 96.875 (85.298)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [44/1141]\tLoss 2.4087 (1.7413)\tPrec@1 40.625 (51.667)\tPrec@5 81.250 (85.208)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [45/1141]\tLoss 1.8179 (1.7430)\tPrec@1 62.500 (51.902)\tPrec@5 78.125 (85.054)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [46/1141]\tLoss 0.5171 (1.7169)\tPrec@1 81.250 (52.527)\tPrec@5 100.000 (85.372)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [47/1141]\tLoss 0.6803 (1.6953)\tPrec@1 81.250 (53.125)\tPrec@5 96.875 (85.612)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [48/1141]\tLoss 0.3357 (1.6676)\tPrec@1 93.750 (53.954)\tPrec@5 100.000 (85.906)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [49/1141]\tLoss 0.4243 (1.6427)\tPrec@1 90.625 (54.688)\tPrec@5 100.000 (86.188)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [50/1141]\tLoss 1.3394 (1.6368)\tPrec@1 68.750 (54.963)\tPrec@5 96.875 (86.397)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [51/1141]\tLoss 1.2066 (1.6285)\tPrec@1 62.500 (55.108)\tPrec@5 96.875 (86.599)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [52/1141]\tLoss 0.9583 (1.6158)\tPrec@1 62.500 (55.248)\tPrec@5 100.000 (86.851)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [53/1141]\tLoss 0.6751 (1.5984)\tPrec@1 81.250 (55.729)\tPrec@5 100.000 (87.095)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [54/1141]\tLoss 1.1830 (1.5909)\tPrec@1 65.625 (55.909)\tPrec@5 93.750 (87.216)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [55/1141]\tLoss 0.4612 (1.5707)\tPrec@1 78.125 (56.306)\tPrec@5 100.000 (87.444)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [56/1141]\tLoss 0.4079 (1.5503)\tPrec@1 81.250 (56.743)\tPrec@5 100.000 (87.664)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [57/1141]\tLoss 1.8918 (1.5562)\tPrec@1 62.500 (56.843)\tPrec@5 81.250 (87.554)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [58/1141]\tLoss 0.2465 (1.5340)\tPrec@1 93.750 (57.468)\tPrec@5 100.000 (87.765)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [59/1141]\tLoss 2.0298 (1.5423)\tPrec@1 50.000 (57.344)\tPrec@5 81.250 (87.656)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [60/1141]\tLoss 2.3080 (1.5548)\tPrec@1 53.125 (57.275)\tPrec@5 78.125 (87.500)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [61/1141]\tLoss 2.0941 (1.5635)\tPrec@1 40.625 (57.006)\tPrec@5 71.875 (87.248)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [62/1141]\tLoss 1.8926 (1.5687)\tPrec@1 53.125 (56.944)\tPrec@5 81.250 (87.153)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [63/1141]\tLoss 2.1380 (1.5776)\tPrec@1 40.625 (56.689)\tPrec@5 87.500 (87.158)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [64/1141]\tLoss 2.3491 (1.5895)\tPrec@1 43.750 (56.490)\tPrec@5 71.875 (86.923)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [65/1141]\tLoss 2.6099 (1.6050)\tPrec@1 25.000 (56.013)\tPrec@5 59.375 (86.506)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [66/1141]\tLoss 2.9614 (1.6252)\tPrec@1 28.125 (55.597)\tPrec@5 71.875 (86.287)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [67/1141]\tLoss 2.9533 (1.6447)\tPrec@1 18.750 (55.055)\tPrec@5 59.375 (85.892)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [68/1141]\tLoss 3.6344 (1.6736)\tPrec@1 15.625 (54.484)\tPrec@5 56.250 (85.462)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [69/1141]\tLoss 2.2666 (1.6820)\tPrec@1 25.000 (54.062)\tPrec@5 78.125 (85.357)\n",
      "tensor(9.3750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [70/1141]\tLoss 2.7665 (1.6973)\tPrec@1 9.375 (53.433)\tPrec@5 71.875 (85.167)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [71/1141]\tLoss 2.5556 (1.7092)\tPrec@1 25.000 (53.038)\tPrec@5 65.625 (84.896)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [72/1141]\tLoss 2.7305 (1.7232)\tPrec@1 18.750 (52.568)\tPrec@5 78.125 (84.803)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [73/1141]\tLoss 3.1927 (1.7431)\tPrec@1 15.625 (52.069)\tPrec@5 53.125 (84.375)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [74/1141]\tLoss 2.8503 (1.7578)\tPrec@1 9.375 (51.500)\tPrec@5 65.625 (84.125)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [75/1141]\tLoss 1.5560 (1.7552)\tPrec@1 53.125 (51.521)\tPrec@5 93.750 (84.252)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [76/1141]\tLoss 1.3987 (1.7506)\tPrec@1 50.000 (51.502)\tPrec@5 96.875 (84.416)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [77/1141]\tLoss 1.4543 (1.7468)\tPrec@1 50.000 (51.482)\tPrec@5 96.875 (84.575)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [78/1141]\tLoss 1.5761 (1.7446)\tPrec@1 50.000 (51.464)\tPrec@5 93.750 (84.691)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [79/1141]\tLoss 1.3535 (1.7397)\tPrec@1 50.000 (51.445)\tPrec@5 90.625 (84.766)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [80/1141]\tLoss 1.6720 (1.7389)\tPrec@1 56.250 (51.505)\tPrec@5 93.750 (84.877)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [81/1141]\tLoss 0.9928 (1.7298)\tPrec@1 71.875 (51.753)\tPrec@5 90.625 (84.947)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [82/1141]\tLoss 1.3978 (1.7258)\tPrec@1 65.625 (51.920)\tPrec@5 87.500 (84.977)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [83/1141]\tLoss 0.9236 (1.7162)\tPrec@1 81.250 (52.269)\tPrec@5 96.875 (85.119)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [84/1141]\tLoss 1.4772 (1.7134)\tPrec@1 62.500 (52.390)\tPrec@5 81.250 (85.074)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [85/1141]\tLoss 1.4592 (1.7105)\tPrec@1 62.500 (52.507)\tPrec@5 93.750 (85.174)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [86/1141]\tLoss 1.9860 (1.7136)\tPrec@1 40.625 (52.371)\tPrec@5 90.625 (85.237)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [87/1141]\tLoss 1.8521 (1.7152)\tPrec@1 43.750 (52.273)\tPrec@5 93.750 (85.334)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [88/1141]\tLoss 1.8999 (1.7173)\tPrec@1 50.000 (52.247)\tPrec@5 84.375 (85.323)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [89/1141]\tLoss 1.9153 (1.7195)\tPrec@1 40.625 (52.118)\tPrec@5 87.500 (85.347)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [90/1141]\tLoss 1.2329 (1.7141)\tPrec@1 53.125 (52.129)\tPrec@5 96.875 (85.474)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [91/1141]\tLoss 0.3105 (1.6989)\tPrec@1 87.500 (52.514)\tPrec@5 100.000 (85.632)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [92/1141]\tLoss 0.3694 (1.6846)\tPrec@1 93.750 (52.957)\tPrec@5 96.875 (85.753)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [93/1141]\tLoss 0.3764 (1.6707)\tPrec@1 90.625 (53.358)\tPrec@5 100.000 (85.904)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [94/1141]\tLoss 2.3241 (1.6775)\tPrec@1 56.250 (53.388)\tPrec@5 62.500 (85.658)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [95/1141]\tLoss 1.7252 (1.6780)\tPrec@1 59.375 (53.451)\tPrec@5 81.250 (85.612)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [96/1141]\tLoss 1.9724 (1.6811)\tPrec@1 53.125 (53.447)\tPrec@5 75.000 (85.503)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [97/1141]\tLoss 2.1949 (1.6863)\tPrec@1 56.250 (53.476)\tPrec@5 71.875 (85.364)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [98/1141]\tLoss 1.9463 (1.6889)\tPrec@1 46.875 (53.409)\tPrec@5 81.250 (85.322)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [99/1141]\tLoss 1.9644 (1.6917)\tPrec@1 50.000 (53.375)\tPrec@5 68.750 (85.156)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [100/1141]\tLoss 2.5493 (1.7002)\tPrec@1 34.375 (53.187)\tPrec@5 71.875 (85.025)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [101/1141]\tLoss 1.9922 (1.7030)\tPrec@1 40.625 (53.064)\tPrec@5 78.125 (84.957)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [102/1141]\tLoss 2.3514 (1.7093)\tPrec@1 46.875 (53.004)\tPrec@5 75.000 (84.860)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [103/1141]\tLoss 1.4035 (1.7064)\tPrec@1 62.500 (53.095)\tPrec@5 87.500 (84.886)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [104/1141]\tLoss 1.8791 (1.7080)\tPrec@1 53.125 (53.095)\tPrec@5 81.250 (84.851)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [105/1141]\tLoss 1.6983 (1.7080)\tPrec@1 53.125 (53.096)\tPrec@5 81.250 (84.817)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [106/1141]\tLoss 0.7495 (1.6990)\tPrec@1 75.000 (53.300)\tPrec@5 93.750 (84.901)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [107/1141]\tLoss 0.7235 (1.6900)\tPrec@1 78.125 (53.530)\tPrec@5 93.750 (84.983)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [108/1141]\tLoss 1.2265 (1.6857)\tPrec@1 78.125 (53.756)\tPrec@5 84.375 (84.977)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [109/1141]\tLoss 1.0592 (1.6800)\tPrec@1 71.875 (53.920)\tPrec@5 93.750 (85.057)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [110/1141]\tLoss 0.8533 (1.6726)\tPrec@1 81.250 (54.167)\tPrec@5 87.500 (85.079)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [111/1141]\tLoss 0.8089 (1.6649)\tPrec@1 71.875 (54.325)\tPrec@5 90.625 (85.128)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [112/1141]\tLoss 0.7223 (1.6565)\tPrec@1 87.500 (54.618)\tPrec@5 90.625 (85.177)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [113/1141]\tLoss 0.2256 (1.6440)\tPrec@1 93.750 (54.962)\tPrec@5 100.000 (85.307)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [114/1141]\tLoss 0.5827 (1.6347)\tPrec@1 84.375 (55.217)\tPrec@5 93.750 (85.380)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [115/1141]\tLoss 0.7346 (1.6270)\tPrec@1 84.375 (55.469)\tPrec@5 93.750 (85.453)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [116/1141]\tLoss 1.5122 (1.6260)\tPrec@1 59.375 (55.502)\tPrec@5 87.500 (85.470)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [117/1141]\tLoss 1.8123 (1.6276)\tPrec@1 50.000 (55.456)\tPrec@5 84.375 (85.461)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [118/1141]\tLoss 1.4074 (1.6257)\tPrec@1 53.125 (55.436)\tPrec@5 90.625 (85.504)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [119/1141]\tLoss 1.2442 (1.6225)\tPrec@1 68.750 (55.547)\tPrec@5 90.625 (85.547)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [120/1141]\tLoss 1.2949 (1.6198)\tPrec@1 68.750 (55.656)\tPrec@5 93.750 (85.615)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [121/1141]\tLoss 1.2870 (1.6171)\tPrec@1 68.750 (55.763)\tPrec@5 87.500 (85.630)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [122/1141]\tLoss 2.7863 (1.6266)\tPrec@1 37.500 (55.615)\tPrec@5 65.625 (85.467)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [123/1141]\tLoss 1.9687 (1.6294)\tPrec@1 46.875 (55.544)\tPrec@5 84.375 (85.459)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [124/1141]\tLoss 2.5541 (1.6368)\tPrec@1 31.250 (55.350)\tPrec@5 81.250 (85.425)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [125/1141]\tLoss 1.4916 (1.6356)\tPrec@1 65.625 (55.432)\tPrec@5 87.500 (85.441)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [126/1141]\tLoss 2.1173 (1.6394)\tPrec@1 53.125 (55.413)\tPrec@5 84.375 (85.433)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [127/1141]\tLoss 2.1987 (1.6438)\tPrec@1 46.875 (55.347)\tPrec@5 84.375 (85.425)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [128/1141]\tLoss 1.8078 (1.6451)\tPrec@1 59.375 (55.378)\tPrec@5 87.500 (85.441)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [129/1141]\tLoss 1.0252 (1.6403)\tPrec@1 75.000 (55.529)\tPrec@5 100.000 (85.553)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [130/1141]\tLoss 1.3703 (1.6382)\tPrec@1 65.625 (55.606)\tPrec@5 90.625 (85.592)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [131/1141]\tLoss 0.7221 (1.6313)\tPrec@1 81.250 (55.800)\tPrec@5 100.000 (85.701)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [132/1141]\tLoss 0.6457 (1.6239)\tPrec@1 75.000 (55.945)\tPrec@5 96.875 (85.785)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [133/1141]\tLoss 0.7833 (1.6176)\tPrec@1 81.250 (56.133)\tPrec@5 93.750 (85.844)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [134/1141]\tLoss 1.8554 (1.6194)\tPrec@1 43.750 (56.042)\tPrec@5 90.625 (85.880)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [135/1141]\tLoss 2.6208 (1.6267)\tPrec@1 21.875 (55.790)\tPrec@5 78.125 (85.823)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [136/1141]\tLoss 3.5348 (1.6407)\tPrec@1 25.000 (55.566)\tPrec@5 59.375 (85.630)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [137/1141]\tLoss 1.7859 (1.6417)\tPrec@1 53.125 (55.548)\tPrec@5 78.125 (85.575)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [138/1141]\tLoss 0.3898 (1.6327)\tPrec@1 93.750 (55.823)\tPrec@5 96.875 (85.656)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [139/1141]\tLoss 0.7125 (1.6261)\tPrec@1 84.375 (56.027)\tPrec@5 93.750 (85.714)\n",
      "tensor(78.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [140/1141]\tLoss 0.8843 (1.6209)\tPrec@1 78.125 (56.184)\tPrec@5 93.750 (85.771)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [141/1141]\tLoss 1.0905 (1.6171)\tPrec@1 59.375 (56.206)\tPrec@5 93.750 (85.827)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [142/1141]\tLoss 0.8214 (1.6116)\tPrec@1 71.875 (56.316)\tPrec@5 100.000 (85.927)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [143/1141]\tLoss 1.3954 (1.6101)\tPrec@1 71.875 (56.424)\tPrec@5 84.375 (85.916)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [144/1141]\tLoss 1.6870 (1.6106)\tPrec@1 43.750 (56.336)\tPrec@5 81.250 (85.884)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [145/1141]\tLoss 2.3969 (1.6160)\tPrec@1 28.125 (56.143)\tPrec@5 87.500 (85.895)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [146/1141]\tLoss 2.4050 (1.6213)\tPrec@1 28.125 (55.952)\tPrec@5 87.500 (85.906)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [147/1141]\tLoss 2.1391 (1.6248)\tPrec@1 46.875 (55.891)\tPrec@5 84.375 (85.895)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [148/1141]\tLoss 1.6570 (1.6251)\tPrec@1 50.000 (55.852)\tPrec@5 96.875 (85.969)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [149/1141]\tLoss 1.7021 (1.6256)\tPrec@1 62.500 (55.896)\tPrec@5 87.500 (85.979)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [150/1141]\tLoss 2.2620 (1.6298)\tPrec@1 31.250 (55.733)\tPrec@5 71.875 (85.886)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [151/1141]\tLoss 1.6387 (1.6298)\tPrec@1 50.000 (55.695)\tPrec@5 87.500 (85.896)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [152/1141]\tLoss 1.6330 (1.6299)\tPrec@1 53.125 (55.678)\tPrec@5 87.500 (85.907)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [153/1141]\tLoss 1.8338 (1.6312)\tPrec@1 46.875 (55.621)\tPrec@5 81.250 (85.877)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [154/1141]\tLoss 2.0500 (1.6339)\tPrec@1 43.750 (55.544)\tPrec@5 87.500 (85.887)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [155/1141]\tLoss 2.1156 (1.6370)\tPrec@1 40.625 (55.449)\tPrec@5 78.125 (85.837)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [156/1141]\tLoss 2.2597 (1.6410)\tPrec@1 43.750 (55.374)\tPrec@5 68.750 (85.729)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [157/1141]\tLoss 1.6067 (1.6407)\tPrec@1 65.625 (55.439)\tPrec@5 78.125 (85.680)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [158/1141]\tLoss 2.2666 (1.6447)\tPrec@1 50.000 (55.405)\tPrec@5 71.875 (85.594)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [159/1141]\tLoss 1.4863 (1.6437)\tPrec@1 50.000 (55.371)\tPrec@5 84.375 (85.586)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [160/1141]\tLoss 1.7598 (1.6444)\tPrec@1 53.125 (55.357)\tPrec@5 81.250 (85.559)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [161/1141]\tLoss 1.6988 (1.6447)\tPrec@1 50.000 (55.324)\tPrec@5 87.500 (85.571)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [162/1141]\tLoss 1.9587 (1.6467)\tPrec@1 40.625 (55.234)\tPrec@5 81.250 (85.544)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [163/1141]\tLoss 1.6149 (1.6465)\tPrec@1 40.625 (55.145)\tPrec@5 93.750 (85.595)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [164/1141]\tLoss 1.4912 (1.6455)\tPrec@1 53.125 (55.133)\tPrec@5 93.750 (85.644)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [165/1141]\tLoss 1.4002 (1.6441)\tPrec@1 53.125 (55.120)\tPrec@5 93.750 (85.693)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [166/1141]\tLoss 2.0208 (1.6463)\tPrec@1 46.875 (55.071)\tPrec@5 84.375 (85.685)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [167/1141]\tLoss 1.7024 (1.6466)\tPrec@1 50.000 (55.041)\tPrec@5 90.625 (85.714)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [168/1141]\tLoss 1.7479 (1.6472)\tPrec@1 56.250 (55.048)\tPrec@5 90.625 (85.743)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [169/1141]\tLoss 2.3539 (1.6514)\tPrec@1 21.875 (54.853)\tPrec@5 62.500 (85.607)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [170/1141]\tLoss 1.6283 (1.6513)\tPrec@1 46.875 (54.806)\tPrec@5 90.625 (85.636)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [171/1141]\tLoss 1.8717 (1.6525)\tPrec@1 46.875 (54.760)\tPrec@5 84.375 (85.629)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [172/1141]\tLoss 1.1922 (1.6499)\tPrec@1 56.250 (54.769)\tPrec@5 96.875 (85.694)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [173/1141]\tLoss 0.9696 (1.6460)\tPrec@1 62.500 (54.813)\tPrec@5 93.750 (85.740)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [174/1141]\tLoss 0.8629 (1.6415)\tPrec@1 65.625 (54.875)\tPrec@5 96.875 (85.804)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [175/1141]\tLoss 2.3544 (1.6455)\tPrec@1 25.000 (54.705)\tPrec@5 81.250 (85.778)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [176/1141]\tLoss 2.1570 (1.6484)\tPrec@1 21.875 (54.520)\tPrec@5 71.875 (85.699)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [177/1141]\tLoss 2.2464 (1.6518)\tPrec@1 25.000 (54.354)\tPrec@5 81.250 (85.674)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [178/1141]\tLoss 2.0083 (1.6538)\tPrec@1 53.125 (54.347)\tPrec@5 81.250 (85.649)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [179/1141]\tLoss 1.8110 (1.6547)\tPrec@1 46.875 (54.306)\tPrec@5 78.125 (85.608)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [180/1141]\tLoss 1.8833 (1.6559)\tPrec@1 53.125 (54.299)\tPrec@5 81.250 (85.584)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [181/1141]\tLoss 1.9939 (1.6578)\tPrec@1 59.375 (54.327)\tPrec@5 84.375 (85.577)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [182/1141]\tLoss 1.4852 (1.6568)\tPrec@1 62.500 (54.372)\tPrec@5 78.125 (85.536)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [183/1141]\tLoss 1.6152 (1.6566)\tPrec@1 65.625 (54.433)\tPrec@5 81.250 (85.513)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [184/1141]\tLoss 1.1359 (1.6538)\tPrec@1 71.875 (54.527)\tPrec@5 87.500 (85.524)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [185/1141]\tLoss 1.3765 (1.6523)\tPrec@1 65.625 (54.587)\tPrec@5 90.625 (85.551)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [186/1141]\tLoss 1.3672 (1.6508)\tPrec@1 65.625 (54.646)\tPrec@5 90.625 (85.578)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [187/1141]\tLoss 2.4346 (1.6550)\tPrec@1 50.000 (54.621)\tPrec@5 81.250 (85.555)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [188/1141]\tLoss 1.6032 (1.6547)\tPrec@1 53.125 (54.613)\tPrec@5 90.625 (85.582)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [189/1141]\tLoss 2.2088 (1.6576)\tPrec@1 31.250 (54.490)\tPrec@5 84.375 (85.576)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [190/1141]\tLoss 1.2621 (1.6555)\tPrec@1 62.500 (54.532)\tPrec@5 90.625 (85.602)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [191/1141]\tLoss 0.6736 (1.6504)\tPrec@1 84.375 (54.688)\tPrec@5 100.000 (85.677)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [192/1141]\tLoss 1.1789 (1.6480)\tPrec@1 68.750 (54.760)\tPrec@5 90.625 (85.703)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [193/1141]\tLoss 1.6598 (1.6480)\tPrec@1 53.125 (54.752)\tPrec@5 84.375 (85.696)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [194/1141]\tLoss 2.6212 (1.6530)\tPrec@1 28.125 (54.615)\tPrec@5 81.250 (85.673)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [195/1141]\tLoss 3.0258 (1.6600)\tPrec@1 9.375 (54.385)\tPrec@5 65.625 (85.571)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [196/1141]\tLoss 2.4453 (1.6640)\tPrec@1 28.125 (54.251)\tPrec@5 71.875 (85.501)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [197/1141]\tLoss 1.3101 (1.6622)\tPrec@1 71.875 (54.340)\tPrec@5 87.500 (85.511)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [198/1141]\tLoss 1.3342 (1.6606)\tPrec@1 62.500 (54.381)\tPrec@5 93.750 (85.553)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [199/1141]\tLoss 1.2733 (1.6586)\tPrec@1 71.875 (54.469)\tPrec@5 93.750 (85.594)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [200/1141]\tLoss 0.8858 (1.6548)\tPrec@1 84.375 (54.618)\tPrec@5 90.625 (85.619)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [201/1141]\tLoss 0.4156 (1.6487)\tPrec@1 93.750 (54.811)\tPrec@5 96.875 (85.675)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [202/1141]\tLoss 0.6121 (1.6436)\tPrec@1 90.625 (54.988)\tPrec@5 90.625 (85.699)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [203/1141]\tLoss 0.3612 (1.6373)\tPrec@1 87.500 (55.147)\tPrec@5 100.000 (85.769)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [204/1141]\tLoss 0.2924 (1.6307)\tPrec@1 87.500 (55.305)\tPrec@5 100.000 (85.838)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [205/1141]\tLoss 0.3440 (1.6245)\tPrec@1 87.500 (55.461)\tPrec@5 96.875 (85.892)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [206/1141]\tLoss 1.8540 (1.6256)\tPrec@1 56.250 (55.465)\tPrec@5 84.375 (85.885)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [207/1141]\tLoss 2.4331 (1.6294)\tPrec@1 37.500 (55.379)\tPrec@5 78.125 (85.847)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [208/1141]\tLoss 2.1681 (1.6320)\tPrec@1 50.000 (55.353)\tPrec@5 78.125 (85.810)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [209/1141]\tLoss 3.0542 (1.6388)\tPrec@1 15.625 (55.164)\tPrec@5 53.125 (85.655)\n",
      "tensor(12.5000, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [210/1141]\tLoss 3.9906 (1.6499)\tPrec@1 12.500 (54.961)\tPrec@5 40.625 (85.441)\n",
      "tensor(3.1250, device='cuda:0')\n",
      "Test: [211/1141]\tLoss 3.7483 (1.6598)\tPrec@1 3.125 (54.717)\tPrec@5 56.250 (85.304)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [212/1141]\tLoss 2.2445 (1.6626)\tPrec@1 46.875 (54.680)\tPrec@5 65.625 (85.211)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [213/1141]\tLoss 0.6475 (1.6578)\tPrec@1 78.125 (54.790)\tPrec@5 93.750 (85.251)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [214/1141]\tLoss 0.5814 (1.6528)\tPrec@1 84.375 (54.927)\tPrec@5 96.875 (85.305)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [215/1141]\tLoss 1.2684 (1.6511)\tPrec@1 68.750 (54.991)\tPrec@5 87.500 (85.315)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [216/1141]\tLoss 2.0391 (1.6528)\tPrec@1 46.875 (54.954)\tPrec@5 96.875 (85.369)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [217/1141]\tLoss 2.0298 (1.6546)\tPrec@1 43.750 (54.903)\tPrec@5 84.375 (85.364)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [218/1141]\tLoss 2.1180 (1.6567)\tPrec@1 43.750 (54.852)\tPrec@5 78.125 (85.331)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [219/1141]\tLoss 0.8280 (1.6529)\tPrec@1 78.125 (54.957)\tPrec@5 96.875 (85.384)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [220/1141]\tLoss 0.8051 (1.6491)\tPrec@1 65.625 (55.006)\tPrec@5 100.000 (85.450)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [221/1141]\tLoss 1.0954 (1.6466)\tPrec@1 71.875 (55.082)\tPrec@5 93.750 (85.487)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [222/1141]\tLoss 1.1713 (1.6445)\tPrec@1 71.875 (55.157)\tPrec@5 84.375 (85.482)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [223/1141]\tLoss 0.9909 (1.6415)\tPrec@1 71.875 (55.232)\tPrec@5 93.750 (85.519)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [224/1141]\tLoss 0.6366 (1.6371)\tPrec@1 81.250 (55.347)\tPrec@5 96.875 (85.569)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [225/1141]\tLoss 2.4170 (1.6405)\tPrec@1 43.750 (55.296)\tPrec@5 68.750 (85.495)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [226/1141]\tLoss 2.0557 (1.6424)\tPrec@1 59.375 (55.314)\tPrec@5 81.250 (85.476)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [227/1141]\tLoss 1.3724 (1.6412)\tPrec@1 62.500 (55.345)\tPrec@5 84.375 (85.471)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [228/1141]\tLoss 2.1966 (1.6436)\tPrec@1 50.000 (55.322)\tPrec@5 71.875 (85.412)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [229/1141]\tLoss 1.4363 (1.6427)\tPrec@1 53.125 (55.312)\tPrec@5 81.250 (85.394)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [230/1141]\tLoss 1.6260 (1.6426)\tPrec@1 59.375 (55.330)\tPrec@5 81.250 (85.376)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [231/1141]\tLoss 1.6053 (1.6425)\tPrec@1 40.625 (55.267)\tPrec@5 87.500 (85.385)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [232/1141]\tLoss 1.9579 (1.6438)\tPrec@1 46.875 (55.231)\tPrec@5 84.375 (85.381)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [233/1141]\tLoss 1.6314 (1.6438)\tPrec@1 53.125 (55.222)\tPrec@5 93.750 (85.417)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [234/1141]\tLoss 3.0764 (1.6499)\tPrec@1 25.000 (55.093)\tPrec@5 59.375 (85.306)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [235/1141]\tLoss 3.1646 (1.6563)\tPrec@1 9.375 (54.899)\tPrec@5 53.125 (85.169)\n",
      "tensor(6.2500, device='cuda:0')\n",
      "Test: [236/1141]\tLoss 2.9354 (1.6617)\tPrec@1 6.250 (54.694)\tPrec@5 65.625 (85.087)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [237/1141]\tLoss 2.6096 (1.6657)\tPrec@1 37.500 (54.622)\tPrec@5 62.500 (84.992)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [238/1141]\tLoss 0.7341 (1.6618)\tPrec@1 75.000 (54.707)\tPrec@5 96.875 (85.042)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [239/1141]\tLoss 1.2272 (1.6600)\tPrec@1 75.000 (54.792)\tPrec@5 90.625 (85.065)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [240/1141]\tLoss 1.7884 (1.6605)\tPrec@1 59.375 (54.811)\tPrec@5 78.125 (85.036)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [241/1141]\tLoss 2.5489 (1.6642)\tPrec@1 50.000 (54.791)\tPrec@5 68.750 (84.969)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [242/1141]\tLoss 3.1371 (1.6702)\tPrec@1 34.375 (54.707)\tPrec@5 40.625 (84.787)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [243/1141]\tLoss 2.7601 (1.6747)\tPrec@1 25.000 (54.585)\tPrec@5 65.625 (84.708)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [244/1141]\tLoss 1.5203 (1.6741)\tPrec@1 53.125 (54.579)\tPrec@5 100.000 (84.770)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [245/1141]\tLoss 2.0938 (1.6758)\tPrec@1 40.625 (54.522)\tPrec@5 81.250 (84.756)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [246/1141]\tLoss 1.8133 (1.6763)\tPrec@1 40.625 (54.466)\tPrec@5 87.500 (84.767)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [247/1141]\tLoss 1.4633 (1.6755)\tPrec@1 59.375 (54.486)\tPrec@5 87.500 (84.778)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [248/1141]\tLoss 1.4280 (1.6745)\tPrec@1 71.875 (54.556)\tPrec@5 90.625 (84.802)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [249/1141]\tLoss 1.8057 (1.6750)\tPrec@1 56.250 (54.563)\tPrec@5 84.375 (84.800)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [250/1141]\tLoss 2.5326 (1.6784)\tPrec@1 31.250 (54.470)\tPrec@5 71.875 (84.749)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [251/1141]\tLoss 2.8266 (1.6830)\tPrec@1 25.000 (54.353)\tPrec@5 78.125 (84.722)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [252/1141]\tLoss 2.1479 (1.6848)\tPrec@1 46.875 (54.323)\tPrec@5 81.250 (84.709)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [253/1141]\tLoss 1.8753 (1.6856)\tPrec@1 37.500 (54.257)\tPrec@5 84.375 (84.707)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [254/1141]\tLoss 2.3077 (1.6880)\tPrec@1 40.625 (54.203)\tPrec@5 81.250 (84.694)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [255/1141]\tLoss 1.8188 (1.6885)\tPrec@1 43.750 (54.163)\tPrec@5 78.125 (84.668)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [256/1141]\tLoss 0.4718 (1.6838)\tPrec@1 87.500 (54.292)\tPrec@5 96.875 (84.715)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [257/1141]\tLoss 0.4124 (1.6788)\tPrec@1 90.625 (54.433)\tPrec@5 96.875 (84.763)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [258/1141]\tLoss 0.3085 (1.6735)\tPrec@1 87.500 (54.561)\tPrec@5 100.000 (84.821)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [259/1141]\tLoss 0.6046 (1.6694)\tPrec@1 90.625 (54.700)\tPrec@5 90.625 (84.844)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [260/1141]\tLoss 0.2102 (1.6638)\tPrec@1 93.750 (54.849)\tPrec@5 100.000 (84.902)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [261/1141]\tLoss 1.1209 (1.6618)\tPrec@1 71.875 (54.914)\tPrec@5 84.375 (84.900)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [262/1141]\tLoss 1.6513 (1.6617)\tPrec@1 59.375 (54.931)\tPrec@5 75.000 (84.862)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [263/1141]\tLoss 1.7740 (1.6622)\tPrec@1 43.750 (54.889)\tPrec@5 87.500 (84.872)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [264/1141]\tLoss 2.2122 (1.6642)\tPrec@1 37.500 (54.823)\tPrec@5 75.000 (84.835)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [265/1141]\tLoss 2.1799 (1.6662)\tPrec@1 50.000 (54.805)\tPrec@5 78.125 (84.810)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [266/1141]\tLoss 1.4052 (1.6652)\tPrec@1 56.250 (54.810)\tPrec@5 90.625 (84.831)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [267/1141]\tLoss 1.0356 (1.6628)\tPrec@1 71.875 (54.874)\tPrec@5 96.875 (84.876)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [268/1141]\tLoss 1.0360 (1.6605)\tPrec@1 68.750 (54.926)\tPrec@5 96.875 (84.921)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [269/1141]\tLoss 1.6360 (1.6604)\tPrec@1 65.625 (54.965)\tPrec@5 78.125 (84.896)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [270/1141]\tLoss 0.7019 (1.6569)\tPrec@1 87.500 (55.085)\tPrec@5 90.625 (84.917)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [271/1141]\tLoss 1.2936 (1.6556)\tPrec@1 71.875 (55.147)\tPrec@5 90.625 (84.938)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [272/1141]\tLoss 2.0301 (1.6569)\tPrec@1 37.500 (55.082)\tPrec@5 84.375 (84.936)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [273/1141]\tLoss 2.4129 (1.6597)\tPrec@1 31.250 (54.995)\tPrec@5 75.000 (84.900)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [274/1141]\tLoss 2.1338 (1.6614)\tPrec@1 37.500 (54.932)\tPrec@5 68.750 (84.841)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [275/1141]\tLoss 1.9209 (1.6623)\tPrec@1 28.125 (54.835)\tPrec@5 87.500 (84.851)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [276/1141]\tLoss 1.7397 (1.6626)\tPrec@1 40.625 (54.783)\tPrec@5 93.750 (84.883)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [277/1141]\tLoss 1.7184 (1.6628)\tPrec@1 37.500 (54.721)\tPrec@5 87.500 (84.892)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [278/1141]\tLoss 1.3270 (1.6616)\tPrec@1 68.750 (54.772)\tPrec@5 90.625 (84.913)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [279/1141]\tLoss 2.0502 (1.6630)\tPrec@1 50.000 (54.754)\tPrec@5 84.375 (84.911)\n",
      "tensor(50., device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [280/1141]\tLoss 1.7039 (1.6632)\tPrec@1 50.000 (54.738)\tPrec@5 96.875 (84.953)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [281/1141]\tLoss 1.0252 (1.6609)\tPrec@1 81.250 (54.832)\tPrec@5 93.750 (84.984)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [282/1141]\tLoss 0.9298 (1.6583)\tPrec@1 71.875 (54.892)\tPrec@5 100.000 (85.038)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [283/1141]\tLoss 1.5109 (1.6578)\tPrec@1 65.625 (54.930)\tPrec@5 87.500 (85.046)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [284/1141]\tLoss 2.2023 (1.6597)\tPrec@1 43.750 (54.890)\tPrec@5 75.000 (85.011)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [285/1141]\tLoss 2.3182 (1.6620)\tPrec@1 34.375 (54.819)\tPrec@5 75.000 (84.976)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [286/1141]\tLoss 2.1401 (1.6637)\tPrec@1 43.750 (54.780)\tPrec@5 71.875 (84.930)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [287/1141]\tLoss 2.4517 (1.6664)\tPrec@1 31.250 (54.698)\tPrec@5 68.750 (84.874)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [288/1141]\tLoss 2.2394 (1.6684)\tPrec@1 34.375 (54.628)\tPrec@5 75.000 (84.840)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [289/1141]\tLoss 1.9616 (1.6694)\tPrec@1 34.375 (54.558)\tPrec@5 81.250 (84.828)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [290/1141]\tLoss 1.9034 (1.6702)\tPrec@1 28.125 (54.467)\tPrec@5 87.500 (84.837)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [291/1141]\tLoss 1.6610 (1.6702)\tPrec@1 56.250 (54.473)\tPrec@5 84.375 (84.835)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [292/1141]\tLoss 1.7028 (1.6703)\tPrec@1 53.125 (54.469)\tPrec@5 84.375 (84.834)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [293/1141]\tLoss 1.5446 (1.6699)\tPrec@1 59.375 (54.486)\tPrec@5 90.625 (84.853)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [294/1141]\tLoss 2.2897 (1.6720)\tPrec@1 34.375 (54.417)\tPrec@5 81.250 (84.841)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [295/1141]\tLoss 2.6888 (1.6754)\tPrec@1 37.500 (54.360)\tPrec@5 56.250 (84.745)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [296/1141]\tLoss 2.4642 (1.6781)\tPrec@1 34.375 (54.293)\tPrec@5 75.000 (84.712)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [297/1141]\tLoss 0.8513 (1.6753)\tPrec@1 75.000 (54.362)\tPrec@5 90.625 (84.732)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [298/1141]\tLoss 1.0355 (1.6731)\tPrec@1 78.125 (54.442)\tPrec@5 93.750 (84.762)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [299/1141]\tLoss 1.0471 (1.6711)\tPrec@1 75.000 (54.510)\tPrec@5 93.750 (84.792)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [300/1141]\tLoss 1.6474 (1.6710)\tPrec@1 62.500 (54.537)\tPrec@5 84.375 (84.790)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [301/1141]\tLoss 1.4376 (1.6702)\tPrec@1 59.375 (54.553)\tPrec@5 93.750 (84.820)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [302/1141]\tLoss 1.4468 (1.6695)\tPrec@1 59.375 (54.569)\tPrec@5 93.750 (84.849)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [303/1141]\tLoss 2.2295 (1.6713)\tPrec@1 31.250 (54.492)\tPrec@5 87.500 (84.858)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [304/1141]\tLoss 2.5275 (1.6741)\tPrec@1 9.375 (54.344)\tPrec@5 84.375 (84.857)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [305/1141]\tLoss 3.0761 (1.6787)\tPrec@1 15.625 (54.218)\tPrec@5 81.250 (84.845)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [306/1141]\tLoss 0.9966 (1.6765)\tPrec@1 78.125 (54.296)\tPrec@5 93.750 (84.874)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [307/1141]\tLoss 0.5183 (1.6727)\tPrec@1 90.625 (54.414)\tPrec@5 96.875 (84.913)\n",
      "tensor(100., device='cuda:0')\n",
      "Test: [308/1141]\tLoss 0.1403 (1.6678)\tPrec@1 100.000 (54.561)\tPrec@5 100.000 (84.962)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [309/1141]\tLoss 2.0534 (1.6690)\tPrec@1 50.000 (54.546)\tPrec@5 75.000 (84.929)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [310/1141]\tLoss 2.6579 (1.6722)\tPrec@1 31.250 (54.471)\tPrec@5 68.750 (84.877)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [311/1141]\tLoss 2.2599 (1.6741)\tPrec@1 31.250 (54.397)\tPrec@5 81.250 (84.866)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [312/1141]\tLoss 2.1964 (1.6757)\tPrec@1 37.500 (54.343)\tPrec@5 65.625 (84.804)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [313/1141]\tLoss 2.4516 (1.6782)\tPrec@1 34.375 (54.279)\tPrec@5 87.500 (84.813)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [314/1141]\tLoss 1.7317 (1.6784)\tPrec@1 46.875 (54.256)\tPrec@5 87.500 (84.821)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [315/1141]\tLoss 1.7029 (1.6784)\tPrec@1 50.000 (54.242)\tPrec@5 87.500 (84.830)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [316/1141]\tLoss 1.4471 (1.6777)\tPrec@1 56.250 (54.249)\tPrec@5 93.750 (84.858)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [317/1141]\tLoss 1.6686 (1.6777)\tPrec@1 34.375 (54.186)\tPrec@5 93.750 (84.886)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [318/1141]\tLoss 1.0618 (1.6758)\tPrec@1 68.750 (54.232)\tPrec@5 100.000 (84.933)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [319/1141]\tLoss 1.4670 (1.6751)\tPrec@1 53.125 (54.229)\tPrec@5 87.500 (84.941)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [320/1141]\tLoss 1.6578 (1.6751)\tPrec@1 59.375 (54.245)\tPrec@5 81.250 (84.930)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [321/1141]\tLoss 1.2881 (1.6739)\tPrec@1 59.375 (54.260)\tPrec@5 96.875 (84.967)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [322/1141]\tLoss 2.3757 (1.6760)\tPrec@1 31.250 (54.189)\tPrec@5 78.125 (84.946)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [323/1141]\tLoss 2.2871 (1.6779)\tPrec@1 46.875 (54.167)\tPrec@5 78.125 (84.925)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [324/1141]\tLoss 2.9613 (1.6819)\tPrec@1 37.500 (54.115)\tPrec@5 56.250 (84.837)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [325/1141]\tLoss 0.7497 (1.6790)\tPrec@1 71.875 (54.170)\tPrec@5 96.875 (84.873)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [326/1141]\tLoss 1.2206 (1.6776)\tPrec@1 62.500 (54.195)\tPrec@5 93.750 (84.901)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [327/1141]\tLoss 1.2625 (1.6763)\tPrec@1 62.500 (54.221)\tPrec@5 93.750 (84.928)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [328/1141]\tLoss 1.6811 (1.6763)\tPrec@1 59.375 (54.236)\tPrec@5 84.375 (84.926)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [329/1141]\tLoss 1.3103 (1.6752)\tPrec@1 68.750 (54.280)\tPrec@5 96.875 (84.962)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [330/1141]\tLoss 0.6980 (1.6723)\tPrec@1 75.000 (54.343)\tPrec@5 100.000 (85.008)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [331/1141]\tLoss 1.1642 (1.6708)\tPrec@1 68.750 (54.386)\tPrec@5 96.875 (85.043)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [332/1141]\tLoss 1.2140 (1.6694)\tPrec@1 65.625 (54.420)\tPrec@5 93.750 (85.069)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [333/1141]\tLoss 1.3128 (1.6683)\tPrec@1 62.500 (54.444)\tPrec@5 90.625 (85.086)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [334/1141]\tLoss 2.4207 (1.6706)\tPrec@1 37.500 (54.394)\tPrec@5 78.125 (85.065)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [335/1141]\tLoss 2.5731 (1.6732)\tPrec@1 25.000 (54.306)\tPrec@5 68.750 (85.017)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [336/1141]\tLoss 2.6503 (1.6761)\tPrec@1 34.375 (54.247)\tPrec@5 81.250 (85.006)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [337/1141]\tLoss 2.0093 (1.6771)\tPrec@1 59.375 (54.262)\tPrec@5 81.250 (84.994)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [338/1141]\tLoss 2.0018 (1.6781)\tPrec@1 59.375 (54.277)\tPrec@5 71.875 (84.956)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [339/1141]\tLoss 2.5417 (1.6806)\tPrec@1 31.250 (54.210)\tPrec@5 81.250 (84.945)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [340/1141]\tLoss 2.3603 (1.6826)\tPrec@1 34.375 (54.151)\tPrec@5 71.875 (84.907)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [341/1141]\tLoss 3.3072 (1.6874)\tPrec@1 18.750 (54.048)\tPrec@5 62.500 (84.841)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [342/1141]\tLoss 2.8309 (1.6907)\tPrec@1 21.875 (53.954)\tPrec@5 62.500 (84.776)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [343/1141]\tLoss 2.3389 (1.6926)\tPrec@1 46.875 (53.934)\tPrec@5 65.625 (84.720)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [344/1141]\tLoss 1.8241 (1.6930)\tPrec@1 50.000 (53.922)\tPrec@5 81.250 (84.710)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [345/1141]\tLoss 1.9127 (1.6936)\tPrec@1 46.875 (53.902)\tPrec@5 81.250 (84.700)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [346/1141]\tLoss 2.0998 (1.6948)\tPrec@1 50.000 (53.890)\tPrec@5 78.125 (84.681)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [347/1141]\tLoss 1.0820 (1.6930)\tPrec@1 68.750 (53.933)\tPrec@5 90.625 (84.698)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [348/1141]\tLoss 0.9697 (1.6909)\tPrec@1 75.000 (53.994)\tPrec@5 93.750 (84.724)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [349/1141]\tLoss 0.9487 (1.6888)\tPrec@1 75.000 (54.054)\tPrec@5 93.750 (84.750)\n",
      "tensor(53.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [350/1141]\tLoss 1.9066 (1.6894)\tPrec@1 53.125 (54.051)\tPrec@5 78.125 (84.731)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [351/1141]\tLoss 1.8127 (1.6898)\tPrec@1 53.125 (54.048)\tPrec@5 81.250 (84.721)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [352/1141]\tLoss 0.8737 (1.6875)\tPrec@1 75.000 (54.108)\tPrec@5 93.750 (84.747)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [353/1141]\tLoss 0.7743 (1.6849)\tPrec@1 78.125 (54.175)\tPrec@5 93.750 (84.772)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [354/1141]\tLoss 1.4956 (1.6844)\tPrec@1 68.750 (54.217)\tPrec@5 78.125 (84.754)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [355/1141]\tLoss 1.1980 (1.6830)\tPrec@1 65.625 (54.249)\tPrec@5 90.625 (84.770)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [356/1141]\tLoss 1.2592 (1.6818)\tPrec@1 59.375 (54.263)\tPrec@5 90.625 (84.786)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [357/1141]\tLoss 2.5885 (1.6843)\tPrec@1 31.250 (54.199)\tPrec@5 71.875 (84.750)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [358/1141]\tLoss 2.3746 (1.6863)\tPrec@1 28.125 (54.126)\tPrec@5 78.125 (84.732)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [359/1141]\tLoss 2.4831 (1.6885)\tPrec@1 25.000 (54.045)\tPrec@5 78.125 (84.714)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [360/1141]\tLoss 1.9543 (1.6892)\tPrec@1 40.625 (54.008)\tPrec@5 93.750 (84.739)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [361/1141]\tLoss 2.3601 (1.6911)\tPrec@1 28.125 (53.936)\tPrec@5 81.250 (84.729)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [362/1141]\tLoss 4.4717 (1.6987)\tPrec@1 18.750 (53.840)\tPrec@5 68.750 (84.685)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [363/1141]\tLoss 6.5919 (1.7122)\tPrec@1 9.375 (53.717)\tPrec@5 53.125 (84.598)\n",
      "tensor(3.1250, device='cuda:0')\n",
      "Test: [364/1141]\tLoss 7.2022 (1.7272)\tPrec@1 3.125 (53.579)\tPrec@5 43.750 (84.486)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [365/1141]\tLoss 5.7129 (1.7381)\tPrec@1 9.375 (53.458)\tPrec@5 43.750 (84.375)\n",
      "tensor(6.2500, device='cuda:0')\n",
      "Test: [366/1141]\tLoss 4.6293 (1.7460)\tPrec@1 6.250 (53.329)\tPrec@5 34.375 (84.239)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [367/1141]\tLoss 4.7315 (1.7541)\tPrec@1 0.000 (53.184)\tPrec@5 43.750 (84.129)\n",
      "tensor(3.1250, device='cuda:0')\n",
      "Test: [368/1141]\tLoss 5.0392 (1.7630)\tPrec@1 3.125 (53.049)\tPrec@5 46.875 (84.028)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [369/1141]\tLoss 6.6349 (1.7762)\tPrec@1 0.000 (52.905)\tPrec@5 21.875 (83.860)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [370/1141]\tLoss 5.6817 (1.7867)\tPrec@1 9.375 (52.788)\tPrec@5 25.000 (83.701)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [371/1141]\tLoss 5.6833 (1.7972)\tPrec@1 0.000 (52.646)\tPrec@5 28.125 (83.552)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [372/1141]\tLoss 2.0589 (1.7979)\tPrec@1 31.250 (52.589)\tPrec@5 84.375 (83.554)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [373/1141]\tLoss 3.0662 (1.8013)\tPrec@1 28.125 (52.523)\tPrec@5 62.500 (83.498)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [374/1141]\tLoss 2.3201 (1.8026)\tPrec@1 37.500 (52.483)\tPrec@5 81.250 (83.492)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [375/1141]\tLoss 2.2037 (1.8037)\tPrec@1 34.375 (52.435)\tPrec@5 87.500 (83.502)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [376/1141]\tLoss 2.3924 (1.8053)\tPrec@1 21.875 (52.354)\tPrec@5 84.375 (83.505)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [377/1141]\tLoss 2.2110 (1.8063)\tPrec@1 25.000 (52.282)\tPrec@5 81.250 (83.499)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [378/1141]\tLoss 2.4236 (1.8080)\tPrec@1 46.875 (52.267)\tPrec@5 75.000 (83.476)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [379/1141]\tLoss 1.5615 (1.8073)\tPrec@1 56.250 (52.278)\tPrec@5 81.250 (83.470)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [380/1141]\tLoss 2.4388 (1.8090)\tPrec@1 40.625 (52.247)\tPrec@5 68.750 (83.432)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [381/1141]\tLoss 1.2015 (1.8074)\tPrec@1 62.500 (52.274)\tPrec@5 90.625 (83.451)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [382/1141]\tLoss 1.7399 (1.8072)\tPrec@1 53.125 (52.276)\tPrec@5 87.500 (83.461)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [383/1141]\tLoss 1.8781 (1.8074)\tPrec@1 43.750 (52.254)\tPrec@5 87.500 (83.472)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [384/1141]\tLoss 1.2607 (1.8060)\tPrec@1 59.375 (52.273)\tPrec@5 87.500 (83.482)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [385/1141]\tLoss 1.0050 (1.8039)\tPrec@1 75.000 (52.332)\tPrec@5 93.750 (83.509)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [386/1141]\tLoss 1.8069 (1.8039)\tPrec@1 59.375 (52.350)\tPrec@5 84.375 (83.511)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [387/1141]\tLoss 1.7024 (1.8037)\tPrec@1 56.250 (52.360)\tPrec@5 84.375 (83.513)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [388/1141]\tLoss 1.8829 (1.8039)\tPrec@1 40.625 (52.330)\tPrec@5 87.500 (83.523)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [389/1141]\tLoss 2.2410 (1.8050)\tPrec@1 34.375 (52.284)\tPrec@5 81.250 (83.518)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [390/1141]\tLoss 1.5717 (1.8044)\tPrec@1 53.125 (52.286)\tPrec@5 90.625 (83.536)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [391/1141]\tLoss 1.4481 (1.8035)\tPrec@1 50.000 (52.280)\tPrec@5 96.875 (83.570)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [392/1141]\tLoss 2.1558 (1.8044)\tPrec@1 34.375 (52.234)\tPrec@5 81.250 (83.564)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [393/1141]\tLoss 2.0330 (1.8050)\tPrec@1 37.500 (52.197)\tPrec@5 84.375 (83.566)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [394/1141]\tLoss 1.2302 (1.8035)\tPrec@1 62.500 (52.223)\tPrec@5 93.750 (83.592)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [395/1141]\tLoss 1.9529 (1.8039)\tPrec@1 59.375 (52.241)\tPrec@5 84.375 (83.594)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [396/1141]\tLoss 1.8401 (1.8040)\tPrec@1 46.875 (52.228)\tPrec@5 90.625 (83.611)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [397/1141]\tLoss 1.6313 (1.8035)\tPrec@1 43.750 (52.206)\tPrec@5 90.625 (83.629)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [398/1141]\tLoss 2.1783 (1.8045)\tPrec@1 25.000 (52.138)\tPrec@5 90.625 (83.647)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [399/1141]\tLoss 2.0904 (1.8052)\tPrec@1 34.375 (52.094)\tPrec@5 84.375 (83.648)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [400/1141]\tLoss 1.9181 (1.8055)\tPrec@1 28.125 (52.034)\tPrec@5 81.250 (83.642)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [401/1141]\tLoss 2.2171 (1.8065)\tPrec@1 28.125 (51.975)\tPrec@5 78.125 (83.629)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [402/1141]\tLoss 2.6690 (1.8086)\tPrec@1 18.750 (51.892)\tPrec@5 75.000 (83.607)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [403/1141]\tLoss 1.8494 (1.8087)\tPrec@1 50.000 (51.887)\tPrec@5 90.625 (83.625)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [404/1141]\tLoss 1.6321 (1.8083)\tPrec@1 65.625 (51.921)\tPrec@5 84.375 (83.627)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [405/1141]\tLoss 1.1759 (1.8067)\tPrec@1 65.625 (51.955)\tPrec@5 93.750 (83.651)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [406/1141]\tLoss 2.8908 (1.8094)\tPrec@1 28.125 (51.896)\tPrec@5 68.750 (83.615)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [407/1141]\tLoss 1.9024 (1.8096)\tPrec@1 37.500 (51.861)\tPrec@5 93.750 (83.640)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [408/1141]\tLoss 1.7025 (1.8094)\tPrec@1 37.500 (51.826)\tPrec@5 90.625 (83.657)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [409/1141]\tLoss 1.8637 (1.8095)\tPrec@1 50.000 (51.822)\tPrec@5 87.500 (83.666)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [410/1141]\tLoss 1.2809 (1.8082)\tPrec@1 78.125 (51.886)\tPrec@5 87.500 (83.675)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [411/1141]\tLoss 1.7841 (1.8082)\tPrec@1 53.125 (51.889)\tPrec@5 75.000 (83.654)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [412/1141]\tLoss 1.9870 (1.8086)\tPrec@1 62.500 (51.914)\tPrec@5 81.250 (83.649)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [413/1141]\tLoss 1.8792 (1.8088)\tPrec@1 40.625 (51.887)\tPrec@5 81.250 (83.643)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [414/1141]\tLoss 2.3809 (1.8101)\tPrec@1 28.125 (51.830)\tPrec@5 75.000 (83.622)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [415/1141]\tLoss 2.0653 (1.8108)\tPrec@1 37.500 (51.795)\tPrec@5 84.375 (83.624)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [416/1141]\tLoss 2.4156 (1.8122)\tPrec@1 37.500 (51.761)\tPrec@5 81.250 (83.618)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [417/1141]\tLoss 2.2955 (1.8134)\tPrec@1 46.875 (51.749)\tPrec@5 78.125 (83.605)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [418/1141]\tLoss 1.9714 (1.8137)\tPrec@1 43.750 (51.730)\tPrec@5 84.375 (83.607)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [419/1141]\tLoss 1.8299 (1.8138)\tPrec@1 46.875 (51.719)\tPrec@5 87.500 (83.616)\n",
      "tensor(37.5000, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [420/1141]\tLoss 1.9502 (1.8141)\tPrec@1 37.500 (51.685)\tPrec@5 84.375 (83.618)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [421/1141]\tLoss 2.2344 (1.8151)\tPrec@1 34.375 (51.644)\tPrec@5 81.250 (83.612)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [422/1141]\tLoss 1.2486 (1.8138)\tPrec@1 75.000 (51.699)\tPrec@5 90.625 (83.629)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [423/1141]\tLoss 0.7620 (1.8113)\tPrec@1 84.375 (51.776)\tPrec@5 93.750 (83.653)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [424/1141]\tLoss 0.7185 (1.8087)\tPrec@1 78.125 (51.838)\tPrec@5 96.875 (83.684)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [425/1141]\tLoss 1.2684 (1.8074)\tPrec@1 68.750 (51.878)\tPrec@5 84.375 (83.685)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [426/1141]\tLoss 1.3628 (1.8064)\tPrec@1 62.500 (51.903)\tPrec@5 93.750 (83.709)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [427/1141]\tLoss 1.6628 (1.8061)\tPrec@1 56.250 (51.913)\tPrec@5 90.625 (83.725)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [428/1141]\tLoss 1.6865 (1.8058)\tPrec@1 59.375 (51.930)\tPrec@5 84.375 (83.727)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [429/1141]\tLoss 1.2321 (1.8044)\tPrec@1 68.750 (51.969)\tPrec@5 93.750 (83.750)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [430/1141]\tLoss 1.6573 (1.8041)\tPrec@1 50.000 (51.965)\tPrec@5 78.125 (83.737)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [431/1141]\tLoss 2.5365 (1.8058)\tPrec@1 25.000 (51.902)\tPrec@5 81.250 (83.731)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [432/1141]\tLoss 2.6047 (1.8076)\tPrec@1 18.750 (51.826)\tPrec@5 78.125 (83.718)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [433/1141]\tLoss 2.6086 (1.8095)\tPrec@1 31.250 (51.779)\tPrec@5 75.000 (83.698)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [434/1141]\tLoss 2.3342 (1.8107)\tPrec@1 34.375 (51.739)\tPrec@5 87.500 (83.707)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [435/1141]\tLoss 2.6194 (1.8125)\tPrec@1 43.750 (51.720)\tPrec@5 62.500 (83.658)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [436/1141]\tLoss 2.7725 (1.8147)\tPrec@1 28.125 (51.666)\tPrec@5 62.500 (83.610)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [437/1141]\tLoss 2.3785 (1.8160)\tPrec@1 31.250 (51.620)\tPrec@5 75.000 (83.590)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [438/1141]\tLoss 1.8414 (1.8161)\tPrec@1 56.250 (51.630)\tPrec@5 90.625 (83.606)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [439/1141]\tLoss 2.0548 (1.8166)\tPrec@1 50.000 (51.626)\tPrec@5 81.250 (83.601)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [440/1141]\tLoss 4.8644 (1.8235)\tPrec@1 25.000 (51.566)\tPrec@5 50.000 (83.525)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [441/1141]\tLoss 8.6623 (1.8390)\tPrec@1 0.000 (51.449)\tPrec@5 3.125 (83.343)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [442/1141]\tLoss 9.6916 (1.8567)\tPrec@1 0.000 (51.333)\tPrec@5 0.000 (83.155)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [443/1141]\tLoss 8.1653 (1.8710)\tPrec@1 0.000 (51.218)\tPrec@5 0.000 (82.967)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [444/1141]\tLoss 6.4738 (1.8813)\tPrec@1 0.000 (51.103)\tPrec@5 3.125 (82.788)\n",
      "tensor(0., device='cuda:0')\n",
      "Test: [445/1141]\tLoss 6.2373 (1.8911)\tPrec@1 0.000 (50.988)\tPrec@5 0.000 (82.602)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [446/1141]\tLoss 5.0440 (1.8981)\tPrec@1 9.375 (50.895)\tPrec@5 18.750 (82.459)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [447/1141]\tLoss 0.7352 (1.8955)\tPrec@1 90.625 (50.984)\tPrec@5 93.750 (82.485)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [448/1141]\tLoss 0.4148 (1.8922)\tPrec@1 93.750 (51.079)\tPrec@5 96.875 (82.517)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [449/1141]\tLoss 0.7334 (1.8896)\tPrec@1 78.125 (51.139)\tPrec@5 96.875 (82.549)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [450/1141]\tLoss 0.8375 (1.8873)\tPrec@1 84.375 (51.213)\tPrec@5 93.750 (82.573)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [451/1141]\tLoss 1.7341 (1.8870)\tPrec@1 62.500 (51.238)\tPrec@5 78.125 (82.564)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [452/1141]\tLoss 2.3119 (1.8879)\tPrec@1 56.250 (51.249)\tPrec@5 65.625 (82.526)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [453/1141]\tLoss 1.5707 (1.8872)\tPrec@1 62.500 (51.273)\tPrec@5 81.250 (82.523)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [454/1141]\tLoss 1.3060 (1.8859)\tPrec@1 59.375 (51.291)\tPrec@5 93.750 (82.548)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [455/1141]\tLoss 1.7096 (1.8855)\tPrec@1 50.000 (51.288)\tPrec@5 84.375 (82.552)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [456/1141]\tLoss 2.6932 (1.8873)\tPrec@1 21.875 (51.224)\tPrec@5 71.875 (82.529)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [457/1141]\tLoss 2.6872 (1.8891)\tPrec@1 25.000 (51.167)\tPrec@5 78.125 (82.519)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [458/1141]\tLoss 2.8850 (1.8912)\tPrec@1 21.875 (51.103)\tPrec@5 68.750 (82.489)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [459/1141]\tLoss 1.3534 (1.8901)\tPrec@1 56.250 (51.114)\tPrec@5 93.750 (82.514)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [460/1141]\tLoss 1.1940 (1.8886)\tPrec@1 71.875 (51.159)\tPrec@5 90.625 (82.531)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [461/1141]\tLoss 0.5740 (1.8857)\tPrec@1 84.375 (51.231)\tPrec@5 96.875 (82.562)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [462/1141]\tLoss 1.5842 (1.8851)\tPrec@1 50.000 (51.228)\tPrec@5 87.500 (82.573)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [463/1141]\tLoss 2.5747 (1.8865)\tPrec@1 37.500 (51.199)\tPrec@5 65.625 (82.536)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [464/1141]\tLoss 1.9356 (1.8866)\tPrec@1 43.750 (51.183)\tPrec@5 90.625 (82.554)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [465/1141]\tLoss 1.9029 (1.8867)\tPrec@1 53.125 (51.187)\tPrec@5 78.125 (82.544)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [466/1141]\tLoss 1.4544 (1.8858)\tPrec@1 65.625 (51.218)\tPrec@5 90.625 (82.562)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [467/1141]\tLoss 1.4327 (1.8848)\tPrec@1 56.250 (51.229)\tPrec@5 100.000 (82.599)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [468/1141]\tLoss 1.1486 (1.8832)\tPrec@1 62.500 (51.253)\tPrec@5 96.875 (82.629)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [469/1141]\tLoss 1.4396 (1.8823)\tPrec@1 68.750 (51.290)\tPrec@5 90.625 (82.646)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [470/1141]\tLoss 1.9614 (1.8824)\tPrec@1 43.750 (51.274)\tPrec@5 78.125 (82.637)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [471/1141]\tLoss 2.4553 (1.8837)\tPrec@1 50.000 (51.271)\tPrec@5 71.875 (82.614)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [472/1141]\tLoss 2.1873 (1.8843)\tPrec@1 37.500 (51.242)\tPrec@5 84.375 (82.618)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [473/1141]\tLoss 2.0208 (1.8846)\tPrec@1 46.875 (51.233)\tPrec@5 84.375 (82.621)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [474/1141]\tLoss 1.9148 (1.8847)\tPrec@1 50.000 (51.230)\tPrec@5 75.000 (82.605)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [475/1141]\tLoss 1.2149 (1.8832)\tPrec@1 62.500 (51.254)\tPrec@5 93.750 (82.629)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [476/1141]\tLoss 1.2195 (1.8819)\tPrec@1 75.000 (51.304)\tPrec@5 87.500 (82.639)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [477/1141]\tLoss 0.9007 (1.8798)\tPrec@1 78.125 (51.360)\tPrec@5 87.500 (82.649)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [478/1141]\tLoss 1.7828 (1.8796)\tPrec@1 62.500 (51.383)\tPrec@5 78.125 (82.640)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [479/1141]\tLoss 2.3887 (1.8807)\tPrec@1 53.125 (51.387)\tPrec@5 75.000 (82.624)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [480/1141]\tLoss 2.4086 (1.8818)\tPrec@1 37.500 (51.358)\tPrec@5 71.875 (82.601)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [481/1141]\tLoss 1.1897 (1.8803)\tPrec@1 75.000 (51.407)\tPrec@5 84.375 (82.605)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [482/1141]\tLoss 0.9266 (1.8783)\tPrec@1 75.000 (51.456)\tPrec@5 93.750 (82.628)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [483/1141]\tLoss 2.1394 (1.8789)\tPrec@1 56.250 (51.466)\tPrec@5 81.250 (82.625)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [484/1141]\tLoss 1.8005 (1.8787)\tPrec@1 62.500 (51.488)\tPrec@5 81.250 (82.622)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [485/1141]\tLoss 0.9248 (1.8768)\tPrec@1 71.875 (51.530)\tPrec@5 93.750 (82.645)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [486/1141]\tLoss 1.5285 (1.8760)\tPrec@1 68.750 (51.566)\tPrec@5 84.375 (82.649)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [487/1141]\tLoss 1.2163 (1.8747)\tPrec@1 71.875 (51.607)\tPrec@5 87.500 (82.659)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [488/1141]\tLoss 2.0894 (1.8751)\tPrec@1 53.125 (51.610)\tPrec@5 75.000 (82.643)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [489/1141]\tLoss 1.6668 (1.8747)\tPrec@1 65.625 (51.639)\tPrec@5 84.375 (82.647)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [490/1141]\tLoss 1.7998 (1.8746)\tPrec@1 56.250 (51.648)\tPrec@5 87.500 (82.657)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [491/1141]\tLoss 0.9724 (1.8727)\tPrec@1 65.625 (51.677)\tPrec@5 93.750 (82.679)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [492/1141]\tLoss 1.2079 (1.8714)\tPrec@1 62.500 (51.699)\tPrec@5 90.625 (82.695)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [493/1141]\tLoss 0.4207 (1.8684)\tPrec@1 90.625 (51.778)\tPrec@5 100.000 (82.730)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [494/1141]\tLoss 1.7366 (1.8682)\tPrec@1 56.250 (51.787)\tPrec@5 81.250 (82.727)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [495/1141]\tLoss 1.1165 (1.8667)\tPrec@1 78.125 (51.840)\tPrec@5 93.750 (82.749)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [496/1141]\tLoss 1.2527 (1.8654)\tPrec@1 68.750 (51.874)\tPrec@5 93.750 (82.772)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [497/1141]\tLoss 1.1563 (1.8640)\tPrec@1 75.000 (51.920)\tPrec@5 87.500 (82.781)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [498/1141]\tLoss 0.7127 (1.8617)\tPrec@1 71.875 (51.960)\tPrec@5 96.875 (82.809)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [499/1141]\tLoss 1.3508 (1.8607)\tPrec@1 62.500 (51.981)\tPrec@5 87.500 (82.819)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [500/1141]\tLoss 2.7968 (1.8625)\tPrec@1 28.125 (51.934)\tPrec@5 68.750 (82.791)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [501/1141]\tLoss 3.2882 (1.8654)\tPrec@1 31.250 (51.892)\tPrec@5 75.000 (82.775)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [502/1141]\tLoss 2.8642 (1.8674)\tPrec@1 28.125 (51.845)\tPrec@5 62.500 (82.735)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [503/1141]\tLoss 2.3293 (1.8683)\tPrec@1 34.375 (51.811)\tPrec@5 81.250 (82.732)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [504/1141]\tLoss 2.1437 (1.8688)\tPrec@1 31.250 (51.770)\tPrec@5 81.250 (82.729)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [505/1141]\tLoss 2.4890 (1.8700)\tPrec@1 40.625 (51.748)\tPrec@5 68.750 (82.701)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [506/1141]\tLoss 2.2729 (1.8708)\tPrec@1 31.250 (51.707)\tPrec@5 81.250 (82.698)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [507/1141]\tLoss 3.2723 (1.8736)\tPrec@1 25.000 (51.655)\tPrec@5 56.250 (82.646)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [508/1141]\tLoss 2.8981 (1.8756)\tPrec@1 18.750 (51.590)\tPrec@5 62.500 (82.607)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [509/1141]\tLoss 1.8115 (1.8755)\tPrec@1 37.500 (51.563)\tPrec@5 90.625 (82.623)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [510/1141]\tLoss 1.6635 (1.8751)\tPrec@1 37.500 (51.535)\tPrec@5 93.750 (82.644)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [511/1141]\tLoss 2.0201 (1.8754)\tPrec@1 31.250 (51.495)\tPrec@5 90.625 (82.660)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [512/1141]\tLoss 1.9160 (1.8754)\tPrec@1 43.750 (51.480)\tPrec@5 84.375 (82.663)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [513/1141]\tLoss 0.6834 (1.8731)\tPrec@1 78.125 (51.532)\tPrec@5 93.750 (82.685)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [514/1141]\tLoss 0.8810 (1.8712)\tPrec@1 78.125 (51.584)\tPrec@5 90.625 (82.700)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [515/1141]\tLoss 0.9714 (1.8694)\tPrec@1 78.125 (51.635)\tPrec@5 93.750 (82.722)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [516/1141]\tLoss 1.9165 (1.8695)\tPrec@1 59.375 (51.650)\tPrec@5 81.250 (82.719)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [517/1141]\tLoss 1.3504 (1.8685)\tPrec@1 62.500 (51.671)\tPrec@5 90.625 (82.734)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [518/1141]\tLoss 2.1959 (1.8692)\tPrec@1 46.875 (51.662)\tPrec@5 84.375 (82.737)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [519/1141]\tLoss 1.4060 (1.8683)\tPrec@1 65.625 (51.689)\tPrec@5 84.375 (82.740)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [520/1141]\tLoss 0.9930 (1.8666)\tPrec@1 71.875 (51.727)\tPrec@5 96.875 (82.768)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [521/1141]\tLoss 1.2980 (1.8655)\tPrec@1 59.375 (51.742)\tPrec@5 90.625 (82.783)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [522/1141]\tLoss 0.8035 (1.8635)\tPrec@1 75.000 (51.787)\tPrec@5 96.875 (82.810)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [523/1141]\tLoss 0.7766 (1.8614)\tPrec@1 78.125 (51.837)\tPrec@5 96.875 (82.836)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [524/1141]\tLoss 0.8513 (1.8595)\tPrec@1 75.000 (51.881)\tPrec@5 93.750 (82.857)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [525/1141]\tLoss 0.7834 (1.8574)\tPrec@1 81.250 (51.937)\tPrec@5 93.750 (82.878)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [526/1141]\tLoss 0.8317 (1.8555)\tPrec@1 81.250 (51.992)\tPrec@5 96.875 (82.904)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [527/1141]\tLoss 1.2899 (1.8544)\tPrec@1 78.125 (52.042)\tPrec@5 87.500 (82.913)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [528/1141]\tLoss 0.5741 (1.8520)\tPrec@1 90.625 (52.115)\tPrec@5 90.625 (82.928)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [529/1141]\tLoss 0.8050 (1.8500)\tPrec@1 81.250 (52.170)\tPrec@5 93.750 (82.948)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [530/1141]\tLoss 0.4726 (1.8474)\tPrec@1 87.500 (52.236)\tPrec@5 100.000 (82.980)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [531/1141]\tLoss 1.0270 (1.8459)\tPrec@1 68.750 (52.267)\tPrec@5 96.875 (83.006)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [532/1141]\tLoss 0.9334 (1.8442)\tPrec@1 75.000 (52.310)\tPrec@5 93.750 (83.027)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [533/1141]\tLoss 0.9052 (1.8424)\tPrec@1 68.750 (52.341)\tPrec@5 93.750 (83.047)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [534/1141]\tLoss 1.4842 (1.8417)\tPrec@1 53.125 (52.342)\tPrec@5 93.750 (83.067)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [535/1141]\tLoss 1.7855 (1.8416)\tPrec@1 56.250 (52.350)\tPrec@5 84.375 (83.069)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [536/1141]\tLoss 2.1423 (1.8422)\tPrec@1 37.500 (52.322)\tPrec@5 87.500 (83.077)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [537/1141]\tLoss 2.3732 (1.8432)\tPrec@1 40.625 (52.300)\tPrec@5 75.000 (83.062)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [538/1141]\tLoss 3.0890 (1.8455)\tPrec@1 25.000 (52.250)\tPrec@5 62.500 (83.024)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [539/1141]\tLoss 2.8152 (1.8473)\tPrec@1 37.500 (52.222)\tPrec@5 62.500 (82.986)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [540/1141]\tLoss 2.4288 (1.8484)\tPrec@1 28.125 (52.178)\tPrec@5 68.750 (82.960)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [541/1141]\tLoss 1.4985 (1.8477)\tPrec@1 65.625 (52.202)\tPrec@5 84.375 (82.962)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [542/1141]\tLoss 1.4835 (1.8471)\tPrec@1 56.250 (52.210)\tPrec@5 87.500 (82.971)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [543/1141]\tLoss 1.4757 (1.8464)\tPrec@1 46.875 (52.200)\tPrec@5 93.750 (82.991)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [544/1141]\tLoss 1.2307 (1.8452)\tPrec@1 59.375 (52.213)\tPrec@5 90.625 (83.005)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [545/1141]\tLoss 0.8760 (1.8435)\tPrec@1 62.500 (52.232)\tPrec@5 100.000 (83.036)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [546/1141]\tLoss 1.8176 (1.8434)\tPrec@1 50.000 (52.228)\tPrec@5 90.625 (83.050)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [547/1141]\tLoss 1.1951 (1.8422)\tPrec@1 59.375 (52.241)\tPrec@5 93.750 (83.069)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [548/1141]\tLoss 1.5396 (1.8417)\tPrec@1 56.250 (52.248)\tPrec@5 81.250 (83.066)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [549/1141]\tLoss 1.4534 (1.8410)\tPrec@1 46.875 (52.239)\tPrec@5 90.625 (83.080)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [550/1141]\tLoss 1.2889 (1.8400)\tPrec@1 56.250 (52.246)\tPrec@5 96.875 (83.105)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [551/1141]\tLoss 1.4212 (1.8392)\tPrec@1 53.125 (52.248)\tPrec@5 84.375 (83.107)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [552/1141]\tLoss 1.3567 (1.8383)\tPrec@1 59.375 (52.260)\tPrec@5 87.500 (83.115)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [553/1141]\tLoss 1.0930 (1.8370)\tPrec@1 71.875 (52.296)\tPrec@5 96.875 (83.140)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [554/1141]\tLoss 1.5328 (1.8364)\tPrec@1 68.750 (52.325)\tPrec@5 81.250 (83.136)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [555/1141]\tLoss 1.3460 (1.8356)\tPrec@1 75.000 (52.366)\tPrec@5 90.625 (83.150)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [556/1141]\tLoss 2.8713 (1.8374)\tPrec@1 25.000 (52.317)\tPrec@5 65.625 (83.118)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [557/1141]\tLoss 2.7686 (1.8391)\tPrec@1 34.375 (52.285)\tPrec@5 65.625 (83.087)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [558/1141]\tLoss 2.8253 (1.8409)\tPrec@1 28.125 (52.242)\tPrec@5 62.500 (83.050)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [559/1141]\tLoss 1.4988 (1.8402)\tPrec@1 62.500 (52.260)\tPrec@5 87.500 (83.058)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [560/1141]\tLoss 1.7802 (1.8401)\tPrec@1 53.125 (52.262)\tPrec@5 84.375 (83.060)\n",
      "tensor(56.2500, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [561/1141]\tLoss 1.5844 (1.8397)\tPrec@1 56.250 (52.269)\tPrec@5 81.250 (83.057)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [562/1141]\tLoss 2.1768 (1.8403)\tPrec@1 43.750 (52.254)\tPrec@5 81.250 (83.054)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [563/1141]\tLoss 2.1508 (1.8408)\tPrec@1 50.000 (52.250)\tPrec@5 68.750 (83.029)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [564/1141]\tLoss 2.1088 (1.8413)\tPrec@1 59.375 (52.262)\tPrec@5 78.125 (83.020)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [565/1141]\tLoss 2.5283 (1.8425)\tPrec@1 40.625 (52.242)\tPrec@5 71.875 (83.000)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [566/1141]\tLoss 2.5745 (1.8438)\tPrec@1 43.750 (52.227)\tPrec@5 71.875 (82.981)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [567/1141]\tLoss 2.2669 (1.8446)\tPrec@1 40.625 (52.206)\tPrec@5 71.875 (82.961)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [568/1141]\tLoss 2.3864 (1.8455)\tPrec@1 28.125 (52.164)\tPrec@5 71.875 (82.942)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [569/1141]\tLoss 1.5629 (1.8450)\tPrec@1 46.875 (52.155)\tPrec@5 90.625 (82.955)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [570/1141]\tLoss 1.0501 (1.8436)\tPrec@1 62.500 (52.173)\tPrec@5 100.000 (82.985)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [571/1141]\tLoss 1.6101 (1.8432)\tPrec@1 56.250 (52.180)\tPrec@5 90.625 (82.998)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [572/1141]\tLoss 2.8199 (1.8449)\tPrec@1 15.625 (52.116)\tPrec@5 68.750 (82.973)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [573/1141]\tLoss 2.6259 (1.8463)\tPrec@1 15.625 (52.052)\tPrec@5 81.250 (82.970)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [574/1141]\tLoss 2.6392 (1.8477)\tPrec@1 18.750 (51.995)\tPrec@5 75.000 (82.957)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [575/1141]\tLoss 1.7495 (1.8475)\tPrec@1 53.125 (51.997)\tPrec@5 84.375 (82.959)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [576/1141]\tLoss 1.7275 (1.8473)\tPrec@1 40.625 (51.977)\tPrec@5 87.500 (82.967)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [577/1141]\tLoss 2.4763 (1.8484)\tPrec@1 34.375 (51.946)\tPrec@5 71.875 (82.948)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [578/1141]\tLoss 1.6523 (1.8480)\tPrec@1 50.000 (51.943)\tPrec@5 81.250 (82.945)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [579/1141]\tLoss 2.7658 (1.8496)\tPrec@1 46.875 (51.934)\tPrec@5 62.500 (82.909)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [580/1141]\tLoss 2.2884 (1.8504)\tPrec@1 50.000 (51.931)\tPrec@5 75.000 (82.896)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [581/1141]\tLoss 2.3464 (1.8512)\tPrec@1 40.625 (51.912)\tPrec@5 68.750 (82.872)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [582/1141]\tLoss 1.3145 (1.8503)\tPrec@1 62.500 (51.930)\tPrec@5 90.625 (82.885)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [583/1141]\tLoss 1.3526 (1.8494)\tPrec@1 59.375 (51.942)\tPrec@5 90.625 (82.898)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [584/1141]\tLoss 1.7036 (1.8492)\tPrec@1 34.375 (51.912)\tPrec@5 90.625 (82.911)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [585/1141]\tLoss 2.0399 (1.8495)\tPrec@1 40.625 (51.893)\tPrec@5 81.250 (82.908)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [586/1141]\tLoss 2.5315 (1.8507)\tPrec@1 31.250 (51.858)\tPrec@5 71.875 (82.890)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [587/1141]\tLoss 1.3666 (1.8499)\tPrec@1 43.750 (51.844)\tPrec@5 96.875 (82.913)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [588/1141]\tLoss 1.1780 (1.8487)\tPrec@1 65.625 (51.868)\tPrec@5 100.000 (82.942)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [589/1141]\tLoss 1.1408 (1.8475)\tPrec@1 56.250 (51.875)\tPrec@5 96.875 (82.966)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [590/1141]\tLoss 0.9771 (1.8460)\tPrec@1 56.250 (51.882)\tPrec@5 100.000 (82.995)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [591/1141]\tLoss 0.8563 (1.8444)\tPrec@1 65.625 (51.906)\tPrec@5 100.000 (83.024)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [592/1141]\tLoss 1.1781 (1.8433)\tPrec@1 59.375 (51.918)\tPrec@5 90.625 (83.036)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [593/1141]\tLoss 1.6003 (1.8428)\tPrec@1 53.125 (51.920)\tPrec@5 87.500 (83.044)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [594/1141]\tLoss 1.0840 (1.8416)\tPrec@1 75.000 (51.959)\tPrec@5 93.750 (83.062)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [595/1141]\tLoss 1.1904 (1.8405)\tPrec@1 62.500 (51.977)\tPrec@5 96.875 (83.085)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [596/1141]\tLoss 0.9884 (1.8390)\tPrec@1 68.750 (52.005)\tPrec@5 96.875 (83.108)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [597/1141]\tLoss 0.9174 (1.8375)\tPrec@1 78.125 (52.048)\tPrec@5 93.750 (83.126)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [598/1141]\tLoss 1.4591 (1.8369)\tPrec@1 56.250 (52.056)\tPrec@5 87.500 (83.133)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [599/1141]\tLoss 0.6313 (1.8349)\tPrec@1 75.000 (52.094)\tPrec@5 93.750 (83.151)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [600/1141]\tLoss 2.4500 (1.8359)\tPrec@1 34.375 (52.064)\tPrec@5 81.250 (83.148)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [601/1141]\tLoss 2.5764 (1.8371)\tPrec@1 25.000 (52.019)\tPrec@5 75.000 (83.134)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [602/1141]\tLoss 1.9571 (1.8373)\tPrec@1 43.750 (52.006)\tPrec@5 87.500 (83.142)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [603/1141]\tLoss 2.8676 (1.8390)\tPrec@1 28.125 (51.966)\tPrec@5 71.875 (83.123)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [604/1141]\tLoss 3.1261 (1.8412)\tPrec@1 28.125 (51.927)\tPrec@5 59.375 (83.084)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [605/1141]\tLoss 3.1300 (1.8433)\tPrec@1 31.250 (51.893)\tPrec@5 56.250 (83.039)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [606/1141]\tLoss 1.6093 (1.8429)\tPrec@1 59.375 (51.905)\tPrec@5 81.250 (83.036)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [607/1141]\tLoss 1.0467 (1.8416)\tPrec@1 75.000 (51.943)\tPrec@5 93.750 (83.054)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [608/1141]\tLoss 1.2609 (1.8406)\tPrec@1 71.875 (51.976)\tPrec@5 87.500 (83.061)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [609/1141]\tLoss 1.2728 (1.8397)\tPrec@1 59.375 (51.988)\tPrec@5 93.750 (83.079)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [610/1141]\tLoss 0.8586 (1.8381)\tPrec@1 78.125 (52.030)\tPrec@5 96.875 (83.101)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [611/1141]\tLoss 0.9830 (1.8367)\tPrec@1 62.500 (52.048)\tPrec@5 100.000 (83.129)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [612/1141]\tLoss 1.4150 (1.8360)\tPrec@1 62.500 (52.065)\tPrec@5 84.375 (83.131)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [613/1141]\tLoss 1.2573 (1.8351)\tPrec@1 65.625 (52.087)\tPrec@5 93.750 (83.148)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [614/1141]\tLoss 1.4034 (1.8344)\tPrec@1 59.375 (52.099)\tPrec@5 78.125 (83.140)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [615/1141]\tLoss 1.3013 (1.8335)\tPrec@1 56.250 (52.105)\tPrec@5 93.750 (83.157)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [616/1141]\tLoss 1.7790 (1.8334)\tPrec@1 53.125 (52.107)\tPrec@5 87.500 (83.165)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [617/1141]\tLoss 2.3858 (1.8343)\tPrec@1 40.625 (52.088)\tPrec@5 81.250 (83.161)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [618/1141]\tLoss 1.6453 (1.8340)\tPrec@1 53.125 (52.090)\tPrec@5 84.375 (83.163)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [619/1141]\tLoss 1.3066 (1.8331)\tPrec@1 65.625 (52.112)\tPrec@5 90.625 (83.175)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [620/1141]\tLoss 0.9678 (1.8318)\tPrec@1 75.000 (52.149)\tPrec@5 87.500 (83.182)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [621/1141]\tLoss 1.2848 (1.8309)\tPrec@1 71.875 (52.180)\tPrec@5 90.625 (83.194)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [622/1141]\tLoss 1.3595 (1.8301)\tPrec@1 65.625 (52.202)\tPrec@5 81.250 (83.191)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [623/1141]\tLoss 1.5964 (1.8297)\tPrec@1 65.625 (52.224)\tPrec@5 78.125 (83.183)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [624/1141]\tLoss 0.6620 (1.8279)\tPrec@1 81.250 (52.270)\tPrec@5 96.875 (83.205)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [625/1141]\tLoss 1.8017 (1.8278)\tPrec@1 65.625 (52.291)\tPrec@5 81.250 (83.202)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [626/1141]\tLoss 0.9011 (1.8264)\tPrec@1 68.750 (52.318)\tPrec@5 100.000 (83.229)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [627/1141]\tLoss 1.0214 (1.8251)\tPrec@1 75.000 (52.354)\tPrec@5 90.625 (83.240)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [628/1141]\tLoss 1.7143 (1.8249)\tPrec@1 62.500 (52.370)\tPrec@5 81.250 (83.237)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [629/1141]\tLoss 1.2592 (1.8240)\tPrec@1 65.625 (52.391)\tPrec@5 90.625 (83.249)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [630/1141]\tLoss 0.7630 (1.8223)\tPrec@1 78.125 (52.432)\tPrec@5 96.875 (83.271)\n",
      "tensor(59.3750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [631/1141]\tLoss 1.7967 (1.8223)\tPrec@1 59.375 (52.443)\tPrec@5 84.375 (83.272)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [632/1141]\tLoss 1.6675 (1.8220)\tPrec@1 46.875 (52.434)\tPrec@5 87.500 (83.279)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [633/1141]\tLoss 1.7180 (1.8219)\tPrec@1 43.750 (52.420)\tPrec@5 87.500 (83.286)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [634/1141]\tLoss 1.4190 (1.8212)\tPrec@1 59.375 (52.431)\tPrec@5 93.750 (83.302)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [635/1141]\tLoss 1.5553 (1.8208)\tPrec@1 50.000 (52.427)\tPrec@5 87.500 (83.309)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [636/1141]\tLoss 1.5668 (1.8204)\tPrec@1 59.375 (52.438)\tPrec@5 87.500 (83.315)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [637/1141]\tLoss 1.8307 (1.8204)\tPrec@1 46.875 (52.429)\tPrec@5 81.250 (83.312)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [638/1141]\tLoss 1.8370 (1.8205)\tPrec@1 37.500 (52.406)\tPrec@5 81.250 (83.309)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [639/1141]\tLoss 1.9755 (1.8207)\tPrec@1 34.375 (52.378)\tPrec@5 84.375 (83.311)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [640/1141]\tLoss 2.8158 (1.8223)\tPrec@1 28.125 (52.340)\tPrec@5 71.875 (83.293)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [641/1141]\tLoss 2.5030 (1.8233)\tPrec@1 21.875 (52.293)\tPrec@5 78.125 (83.285)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [642/1141]\tLoss 2.9271 (1.8250)\tPrec@1 18.750 (52.240)\tPrec@5 59.375 (83.247)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [643/1141]\tLoss 1.7075 (1.8249)\tPrec@1 56.250 (52.247)\tPrec@5 84.375 (83.249)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [644/1141]\tLoss 1.3058 (1.8240)\tPrec@1 68.750 (52.272)\tPrec@5 84.375 (83.251)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [645/1141]\tLoss 1.7017 (1.8239)\tPrec@1 56.250 (52.278)\tPrec@5 84.375 (83.253)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [646/1141]\tLoss 1.9216 (1.8240)\tPrec@1 53.125 (52.280)\tPrec@5 75.000 (83.240)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [647/1141]\tLoss 0.5704 (1.8221)\tPrec@1 81.250 (52.324)\tPrec@5 96.875 (83.261)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [648/1141]\tLoss 0.4414 (1.8199)\tPrec@1 87.500 (52.379)\tPrec@5 96.875 (83.282)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [649/1141]\tLoss 1.1217 (1.8189)\tPrec@1 78.125 (52.418)\tPrec@5 87.500 (83.288)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [650/1141]\tLoss 0.9094 (1.8175)\tPrec@1 59.375 (52.429)\tPrec@5 90.625 (83.300)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [651/1141]\tLoss 0.6496 (1.8157)\tPrec@1 75.000 (52.464)\tPrec@5 96.875 (83.321)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [652/1141]\tLoss 0.7601 (1.8141)\tPrec@1 75.000 (52.498)\tPrec@5 90.625 (83.332)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [653/1141]\tLoss 1.8081 (1.8141)\tPrec@1 50.000 (52.494)\tPrec@5 84.375 (83.333)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [654/1141]\tLoss 1.2360 (1.8132)\tPrec@1 59.375 (52.505)\tPrec@5 100.000 (83.359)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [655/1141]\tLoss 2.1582 (1.8137)\tPrec@1 43.750 (52.491)\tPrec@5 75.000 (83.346)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [656/1141]\tLoss 1.7933 (1.8137)\tPrec@1 50.000 (52.488)\tPrec@5 78.125 (83.338)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [657/1141]\tLoss 1.6174 (1.8134)\tPrec@1 46.875 (52.479)\tPrec@5 96.875 (83.359)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [658/1141]\tLoss 1.8777 (1.8135)\tPrec@1 50.000 (52.475)\tPrec@5 87.500 (83.365)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [659/1141]\tLoss 1.0068 (1.8122)\tPrec@1 68.750 (52.500)\tPrec@5 96.875 (83.385)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [660/1141]\tLoss 0.9943 (1.8110)\tPrec@1 68.750 (52.525)\tPrec@5 96.875 (83.406)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [661/1141]\tLoss 1.3299 (1.8103)\tPrec@1 50.000 (52.521)\tPrec@5 96.875 (83.426)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [662/1141]\tLoss 1.2796 (1.8095)\tPrec@1 62.500 (52.536)\tPrec@5 93.750 (83.442)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [663/1141]\tLoss 2.3839 (1.8103)\tPrec@1 37.500 (52.513)\tPrec@5 78.125 (83.434)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [664/1141]\tLoss 1.3174 (1.8096)\tPrec@1 56.250 (52.519)\tPrec@5 93.750 (83.449)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [665/1141]\tLoss 1.7801 (1.8096)\tPrec@1 56.250 (52.524)\tPrec@5 84.375 (83.451)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [666/1141]\tLoss 2.3275 (1.8103)\tPrec@1 34.375 (52.497)\tPrec@5 68.750 (83.429)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [667/1141]\tLoss 1.7972 (1.8103)\tPrec@1 43.750 (52.484)\tPrec@5 81.250 (83.425)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [668/1141]\tLoss 1.5220 (1.8099)\tPrec@1 65.625 (52.504)\tPrec@5 84.375 (83.427)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [669/1141]\tLoss 0.6967 (1.8082)\tPrec@1 87.500 (52.556)\tPrec@5 90.625 (83.438)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [670/1141]\tLoss 0.9807 (1.8070)\tPrec@1 81.250 (52.599)\tPrec@5 87.500 (83.444)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [671/1141]\tLoss 0.8025 (1.8055)\tPrec@1 81.250 (52.641)\tPrec@5 96.875 (83.464)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [672/1141]\tLoss 2.4896 (1.8065)\tPrec@1 37.500 (52.619)\tPrec@5 75.000 (83.451)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [673/1141]\tLoss 2.6649 (1.8078)\tPrec@1 25.000 (52.578)\tPrec@5 71.875 (83.434)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [674/1141]\tLoss 2.2148 (1.8084)\tPrec@1 31.250 (52.546)\tPrec@5 78.125 (83.426)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [675/1141]\tLoss 1.7577 (1.8083)\tPrec@1 50.000 (52.543)\tPrec@5 90.625 (83.437)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [676/1141]\tLoss 1.4391 (1.8078)\tPrec@1 50.000 (52.539)\tPrec@5 93.750 (83.452)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [677/1141]\tLoss 1.1624 (1.8068)\tPrec@1 56.250 (52.544)\tPrec@5 90.625 (83.462)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [678/1141]\tLoss 2.6066 (1.8080)\tPrec@1 34.375 (52.517)\tPrec@5 81.250 (83.459)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [679/1141]\tLoss 2.9572 (1.8097)\tPrec@1 25.000 (52.477)\tPrec@5 71.875 (83.442)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [680/1141]\tLoss 2.5467 (1.8108)\tPrec@1 21.875 (52.432)\tPrec@5 71.875 (83.425)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [681/1141]\tLoss 2.1050 (1.8112)\tPrec@1 40.625 (52.415)\tPrec@5 84.375 (83.427)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [682/1141]\tLoss 1.7992 (1.8112)\tPrec@1 56.250 (52.420)\tPrec@5 84.375 (83.428)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [683/1141]\tLoss 1.7269 (1.8111)\tPrec@1 34.375 (52.394)\tPrec@5 84.375 (83.429)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [684/1141]\tLoss 0.7501 (1.8095)\tPrec@1 81.250 (52.436)\tPrec@5 100.000 (83.453)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [685/1141]\tLoss 0.9692 (1.8083)\tPrec@1 75.000 (52.469)\tPrec@5 90.625 (83.464)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [686/1141]\tLoss 0.8176 (1.8068)\tPrec@1 78.125 (52.506)\tPrec@5 93.750 (83.479)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [687/1141]\tLoss 2.6649 (1.8081)\tPrec@1 46.875 (52.498)\tPrec@5 75.000 (83.467)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [688/1141]\tLoss 3.0067 (1.8098)\tPrec@1 25.000 (52.458)\tPrec@5 56.250 (83.427)\n",
      "tensor(12.5000, device='cuda:0')\n",
      "Test: [689/1141]\tLoss 3.4680 (1.8122)\tPrec@1 12.500 (52.400)\tPrec@5 50.000 (83.379)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [690/1141]\tLoss 1.8902 (1.8123)\tPrec@1 34.375 (52.374)\tPrec@5 75.000 (83.366)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [691/1141]\tLoss 1.3314 (1.8117)\tPrec@1 68.750 (52.398)\tPrec@5 93.750 (83.382)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [692/1141]\tLoss 1.5218 (1.8112)\tPrec@1 53.125 (52.399)\tPrec@5 90.625 (83.392)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [693/1141]\tLoss 1.8052 (1.8112)\tPrec@1 46.875 (52.391)\tPrec@5 81.250 (83.389)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [694/1141]\tLoss 3.1244 (1.8131)\tPrec@1 34.375 (52.365)\tPrec@5 71.875 (83.372)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [695/1141]\tLoss 2.6943 (1.8144)\tPrec@1 37.500 (52.344)\tPrec@5 65.625 (83.347)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [696/1141]\tLoss 2.5914 (1.8155)\tPrec@1 46.875 (52.336)\tPrec@5 59.375 (83.312)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [697/1141]\tLoss 1.8587 (1.8156)\tPrec@1 53.125 (52.337)\tPrec@5 84.375 (83.314)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [698/1141]\tLoss 2.3081 (1.8163)\tPrec@1 46.875 (52.329)\tPrec@5 81.250 (83.311)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [699/1141]\tLoss 1.9079 (1.8164)\tPrec@1 50.000 (52.326)\tPrec@5 90.625 (83.321)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [700/1141]\tLoss 2.7488 (1.8177)\tPrec@1 18.750 (52.278)\tPrec@5 68.750 (83.301)\n",
      "tensor(37.5000, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [701/1141]\tLoss 2.7024 (1.8190)\tPrec@1 37.500 (52.257)\tPrec@5 71.875 (83.284)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [702/1141]\tLoss 2.7454 (1.8203)\tPrec@1 25.000 (52.218)\tPrec@5 71.875 (83.268)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [703/1141]\tLoss 1.0488 (1.8192)\tPrec@1 71.875 (52.246)\tPrec@5 93.750 (83.283)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [704/1141]\tLoss 1.0044 (1.8180)\tPrec@1 71.875 (52.274)\tPrec@5 93.750 (83.298)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [705/1141]\tLoss 0.5584 (1.8163)\tPrec@1 81.250 (52.315)\tPrec@5 90.625 (83.308)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [706/1141]\tLoss 1.7556 (1.8162)\tPrec@1 53.125 (52.316)\tPrec@5 87.500 (83.314)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [707/1141]\tLoss 2.3424 (1.8169)\tPrec@1 37.500 (52.295)\tPrec@5 81.250 (83.311)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [708/1141]\tLoss 1.3446 (1.8163)\tPrec@1 71.875 (52.323)\tPrec@5 90.625 (83.322)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [709/1141]\tLoss 1.9676 (1.8165)\tPrec@1 50.000 (52.320)\tPrec@5 81.250 (83.319)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [710/1141]\tLoss 0.8419 (1.8151)\tPrec@1 78.125 (52.356)\tPrec@5 93.750 (83.333)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [711/1141]\tLoss 1.6731 (1.8149)\tPrec@1 65.625 (52.374)\tPrec@5 84.375 (83.335)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [712/1141]\tLoss 1.9634 (1.8151)\tPrec@1 46.875 (52.367)\tPrec@5 84.375 (83.336)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [713/1141]\tLoss 1.8707 (1.8152)\tPrec@1 53.125 (52.368)\tPrec@5 90.625 (83.346)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [714/1141]\tLoss 1.8516 (1.8152)\tPrec@1 50.000 (52.365)\tPrec@5 90.625 (83.357)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [715/1141]\tLoss 2.5661 (1.8163)\tPrec@1 34.375 (52.339)\tPrec@5 71.875 (83.341)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [716/1141]\tLoss 1.3395 (1.8156)\tPrec@1 65.625 (52.358)\tPrec@5 93.750 (83.355)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [717/1141]\tLoss 1.8319 (1.8156)\tPrec@1 43.750 (52.346)\tPrec@5 90.625 (83.365)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [718/1141]\tLoss 1.8167 (1.8156)\tPrec@1 46.875 (52.338)\tPrec@5 84.375 (83.367)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [719/1141]\tLoss 1.6390 (1.8154)\tPrec@1 59.375 (52.348)\tPrec@5 84.375 (83.368)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [720/1141]\tLoss 1.3022 (1.8147)\tPrec@1 71.875 (52.375)\tPrec@5 87.500 (83.374)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [721/1141]\tLoss 1.3331 (1.8140)\tPrec@1 65.625 (52.394)\tPrec@5 87.500 (83.380)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [722/1141]\tLoss 2.3948 (1.8148)\tPrec@1 50.000 (52.390)\tPrec@5 68.750 (83.359)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [723/1141]\tLoss 1.8446 (1.8149)\tPrec@1 56.250 (52.396)\tPrec@5 78.125 (83.352)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [724/1141]\tLoss 2.2312 (1.8154)\tPrec@1 59.375 (52.405)\tPrec@5 62.500 (83.323)\n",
      "tensor(12.5000, device='cuda:0')\n",
      "Test: [725/1141]\tLoss 2.6036 (1.8165)\tPrec@1 12.500 (52.350)\tPrec@5 87.500 (83.329)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [726/1141]\tLoss 2.6796 (1.8177)\tPrec@1 18.750 (52.304)\tPrec@5 78.125 (83.322)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [727/1141]\tLoss 3.0976 (1.8195)\tPrec@1 9.375 (52.245)\tPrec@5 71.875 (83.306)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [728/1141]\tLoss 2.3333 (1.8202)\tPrec@1 46.875 (52.238)\tPrec@5 75.000 (83.295)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [729/1141]\tLoss 2.2604 (1.8208)\tPrec@1 37.500 (52.217)\tPrec@5 68.750 (83.275)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [730/1141]\tLoss 1.8697 (1.8208)\tPrec@1 40.625 (52.202)\tPrec@5 81.250 (83.272)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [731/1141]\tLoss 1.5355 (1.8205)\tPrec@1 56.250 (52.207)\tPrec@5 90.625 (83.282)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [732/1141]\tLoss 1.2901 (1.8197)\tPrec@1 53.125 (52.208)\tPrec@5 96.875 (83.301)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [733/1141]\tLoss 1.4255 (1.8192)\tPrec@1 50.000 (52.205)\tPrec@5 84.375 (83.302)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [734/1141]\tLoss 1.5114 (1.8188)\tPrec@1 56.250 (52.211)\tPrec@5 93.750 (83.316)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [735/1141]\tLoss 1.5534 (1.8184)\tPrec@1 53.125 (52.212)\tPrec@5 90.625 (83.326)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [736/1141]\tLoss 1.7049 (1.8183)\tPrec@1 50.000 (52.209)\tPrec@5 93.750 (83.340)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [737/1141]\tLoss 1.8578 (1.8183)\tPrec@1 50.000 (52.206)\tPrec@5 87.500 (83.346)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [738/1141]\tLoss 2.5043 (1.8192)\tPrec@1 28.125 (52.174)\tPrec@5 75.000 (83.335)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [739/1141]\tLoss 2.3473 (1.8200)\tPrec@1 37.500 (52.154)\tPrec@5 75.000 (83.323)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [740/1141]\tLoss 2.7226 (1.8212)\tPrec@1 31.250 (52.126)\tPrec@5 75.000 (83.312)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [741/1141]\tLoss 2.5766 (1.8222)\tPrec@1 34.375 (52.102)\tPrec@5 75.000 (83.301)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [742/1141]\tLoss 3.3051 (1.8242)\tPrec@1 18.750 (52.057)\tPrec@5 65.625 (83.277)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [743/1141]\tLoss 2.6106 (1.8252)\tPrec@1 25.000 (52.020)\tPrec@5 62.500 (83.249)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [744/1141]\tLoss 1.4385 (1.8247)\tPrec@1 50.000 (52.018)\tPrec@5 87.500 (83.255)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [745/1141]\tLoss 1.4759 (1.8243)\tPrec@1 56.250 (52.023)\tPrec@5 93.750 (83.269)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [746/1141]\tLoss 1.8381 (1.8243)\tPrec@1 50.000 (52.021)\tPrec@5 87.500 (83.275)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [747/1141]\tLoss 1.4802 (1.8238)\tPrec@1 53.125 (52.022)\tPrec@5 87.500 (83.280)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [748/1141]\tLoss 1.1286 (1.8229)\tPrec@1 71.875 (52.049)\tPrec@5 90.625 (83.290)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [749/1141]\tLoss 1.4158 (1.8223)\tPrec@1 68.750 (52.071)\tPrec@5 84.375 (83.292)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [750/1141]\tLoss 1.4268 (1.8218)\tPrec@1 71.875 (52.097)\tPrec@5 87.500 (83.297)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [751/1141]\tLoss 1.1932 (1.8210)\tPrec@1 71.875 (52.124)\tPrec@5 90.625 (83.307)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [752/1141]\tLoss 0.9729 (1.8199)\tPrec@1 81.250 (52.162)\tPrec@5 87.500 (83.313)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [753/1141]\tLoss 1.1101 (1.8189)\tPrec@1 68.750 (52.184)\tPrec@5 90.625 (83.322)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [754/1141]\tLoss 1.1560 (1.8180)\tPrec@1 78.125 (52.219)\tPrec@5 84.375 (83.324)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [755/1141]\tLoss 1.1075 (1.8171)\tPrec@1 68.750 (52.240)\tPrec@5 93.750 (83.337)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [756/1141]\tLoss 1.4556 (1.8166)\tPrec@1 65.625 (52.258)\tPrec@5 84.375 (83.339)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [757/1141]\tLoss 1.2549 (1.8159)\tPrec@1 65.625 (52.276)\tPrec@5 90.625 (83.348)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [758/1141]\tLoss 0.9763 (1.8148)\tPrec@1 75.000 (52.306)\tPrec@5 96.875 (83.366)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [759/1141]\tLoss 2.3495 (1.8155)\tPrec@1 21.875 (52.266)\tPrec@5 93.750 (83.380)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [760/1141]\tLoss 2.2599 (1.8161)\tPrec@1 18.750 (52.222)\tPrec@5 84.375 (83.381)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [761/1141]\tLoss 3.0005 (1.8176)\tPrec@1 9.375 (52.165)\tPrec@5 75.000 (83.370)\n",
      "tensor(12.5000, device='cuda:0')\n",
      "Test: [762/1141]\tLoss 2.5068 (1.8185)\tPrec@1 12.500 (52.113)\tPrec@5 81.250 (83.367)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [763/1141]\tLoss 2.0473 (1.8188)\tPrec@1 34.375 (52.090)\tPrec@5 87.500 (83.373)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [764/1141]\tLoss 2.1055 (1.8192)\tPrec@1 21.875 (52.051)\tPrec@5 87.500 (83.378)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [765/1141]\tLoss 2.3151 (1.8198)\tPrec@1 18.750 (52.007)\tPrec@5 84.375 (83.380)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [766/1141]\tLoss 2.5254 (1.8208)\tPrec@1 21.875 (51.968)\tPrec@5 75.000 (83.369)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [767/1141]\tLoss 2.3221 (1.8214)\tPrec@1 18.750 (51.925)\tPrec@5 81.250 (83.366)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [768/1141]\tLoss 2.4402 (1.8222)\tPrec@1 28.125 (51.894)\tPrec@5 75.000 (83.355)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [769/1141]\tLoss 1.6638 (1.8220)\tPrec@1 53.125 (51.895)\tPrec@5 81.250 (83.352)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [770/1141]\tLoss 1.1552 (1.8211)\tPrec@1 68.750 (51.917)\tPrec@5 90.625 (83.362)\n",
      "tensor(62.5000, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [771/1141]\tLoss 1.4164 (1.8206)\tPrec@1 62.500 (51.931)\tPrec@5 87.500 (83.367)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [772/1141]\tLoss 0.9468 (1.8195)\tPrec@1 71.875 (51.957)\tPrec@5 96.875 (83.385)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [773/1141]\tLoss 0.9348 (1.8183)\tPrec@1 75.000 (51.986)\tPrec@5 96.875 (83.402)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [774/1141]\tLoss 0.8314 (1.8171)\tPrec@1 81.250 (52.024)\tPrec@5 93.750 (83.415)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [775/1141]\tLoss 0.7146 (1.8157)\tPrec@1 78.125 (52.058)\tPrec@5 96.875 (83.433)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [776/1141]\tLoss 1.2747 (1.8150)\tPrec@1 59.375 (52.067)\tPrec@5 93.750 (83.446)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [777/1141]\tLoss 1.1446 (1.8141)\tPrec@1 68.750 (52.089)\tPrec@5 93.750 (83.459)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [778/1141]\tLoss 2.0122 (1.8144)\tPrec@1 53.125 (52.090)\tPrec@5 75.000 (83.448)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [779/1141]\tLoss 1.5792 (1.8140)\tPrec@1 59.375 (52.099)\tPrec@5 90.625 (83.458)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [780/1141]\tLoss 1.9573 (1.8142)\tPrec@1 40.625 (52.085)\tPrec@5 78.125 (83.451)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [781/1141]\tLoss 0.7973 (1.8129)\tPrec@1 81.250 (52.122)\tPrec@5 93.750 (83.464)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [782/1141]\tLoss 0.6194 (1.8114)\tPrec@1 84.375 (52.163)\tPrec@5 100.000 (83.485)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [783/1141]\tLoss 0.9063 (1.8103)\tPrec@1 71.875 (52.188)\tPrec@5 96.875 (83.502)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [784/1141]\tLoss 0.9945 (1.8092)\tPrec@1 65.625 (52.205)\tPrec@5 90.625 (83.511)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [785/1141]\tLoss 0.7476 (1.8079)\tPrec@1 75.000 (52.234)\tPrec@5 93.750 (83.524)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [786/1141]\tLoss 1.0343 (1.8069)\tPrec@1 71.875 (52.259)\tPrec@5 87.500 (83.529)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [787/1141]\tLoss 1.7199 (1.8068)\tPrec@1 46.875 (52.253)\tPrec@5 81.250 (83.526)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [788/1141]\tLoss 3.0273 (1.8083)\tPrec@1 15.625 (52.206)\tPrec@5 59.375 (83.496)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [789/1141]\tLoss 2.9916 (1.8098)\tPrec@1 21.875 (52.168)\tPrec@5 50.000 (83.453)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [790/1141]\tLoss 1.6465 (1.8096)\tPrec@1 34.375 (52.145)\tPrec@5 90.625 (83.462)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [791/1141]\tLoss 1.5722 (1.8093)\tPrec@1 53.125 (52.146)\tPrec@5 81.250 (83.460)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [792/1141]\tLoss 1.6390 (1.8091)\tPrec@1 59.375 (52.156)\tPrec@5 78.125 (83.453)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [793/1141]\tLoss 1.7152 (1.8090)\tPrec@1 59.375 (52.165)\tPrec@5 78.125 (83.446)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [794/1141]\tLoss 3.4200 (1.8110)\tPrec@1 31.250 (52.138)\tPrec@5 56.250 (83.412)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [795/1141]\tLoss 2.0476 (1.8113)\tPrec@1 56.250 (52.144)\tPrec@5 84.375 (83.413)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [796/1141]\tLoss 2.4091 (1.8120)\tPrec@1 46.875 (52.137)\tPrec@5 68.750 (83.395)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [797/1141]\tLoss 1.8175 (1.8121)\tPrec@1 43.750 (52.126)\tPrec@5 81.250 (83.392)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [798/1141]\tLoss 0.9005 (1.8109)\tPrec@1 75.000 (52.155)\tPrec@5 93.750 (83.405)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [799/1141]\tLoss 0.8694 (1.8097)\tPrec@1 75.000 (52.184)\tPrec@5 93.750 (83.418)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [800/1141]\tLoss 1.4461 (1.8093)\tPrec@1 68.750 (52.204)\tPrec@5 87.500 (83.423)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [801/1141]\tLoss 1.6804 (1.8091)\tPrec@1 65.625 (52.221)\tPrec@5 87.500 (83.428)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [802/1141]\tLoss 1.4147 (1.8086)\tPrec@1 59.375 (52.230)\tPrec@5 87.500 (83.433)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [803/1141]\tLoss 1.5615 (1.8083)\tPrec@1 50.000 (52.227)\tPrec@5 81.250 (83.431)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [804/1141]\tLoss 1.8653 (1.8084)\tPrec@1 56.250 (52.232)\tPrec@5 81.250 (83.428)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [805/1141]\tLoss 1.4513 (1.8080)\tPrec@1 71.875 (52.257)\tPrec@5 90.625 (83.437)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [806/1141]\tLoss 2.5823 (1.8089)\tPrec@1 31.250 (52.230)\tPrec@5 75.000 (83.426)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [807/1141]\tLoss 2.4943 (1.8098)\tPrec@1 40.625 (52.216)\tPrec@5 78.125 (83.420)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [808/1141]\tLoss 2.7861 (1.8110)\tPrec@1 28.125 (52.186)\tPrec@5 78.125 (83.413)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [809/1141]\tLoss 2.6969 (1.8121)\tPrec@1 37.500 (52.168)\tPrec@5 68.750 (83.395)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [810/1141]\tLoss 1.6580 (1.8119)\tPrec@1 46.875 (52.162)\tPrec@5 93.750 (83.408)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [811/1141]\tLoss 1.7650 (1.8118)\tPrec@1 43.750 (52.151)\tPrec@5 96.875 (83.424)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [812/1141]\tLoss 1.4469 (1.8114)\tPrec@1 53.125 (52.153)\tPrec@5 93.750 (83.437)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [813/1141]\tLoss 1.5347 (1.8110)\tPrec@1 53.125 (52.154)\tPrec@5 87.500 (83.442)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [814/1141]\tLoss 1.7853 (1.8110)\tPrec@1 56.250 (52.159)\tPrec@5 90.625 (83.451)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [815/1141]\tLoss 2.0510 (1.8113)\tPrec@1 40.625 (52.145)\tPrec@5 81.250 (83.448)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [816/1141]\tLoss 3.0259 (1.8128)\tPrec@1 25.000 (52.111)\tPrec@5 65.625 (83.426)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [817/1141]\tLoss 2.7106 (1.8139)\tPrec@1 28.125 (52.082)\tPrec@5 78.125 (83.420)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [818/1141]\tLoss 2.7813 (1.8151)\tPrec@1 28.125 (52.053)\tPrec@5 62.500 (83.394)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [819/1141]\tLoss 2.8015 (1.8163)\tPrec@1 25.000 (52.020)\tPrec@5 68.750 (83.377)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [820/1141]\tLoss 1.7440 (1.8162)\tPrec@1 50.000 (52.017)\tPrec@5 84.375 (83.378)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [821/1141]\tLoss 2.3501 (1.8168)\tPrec@1 40.625 (52.003)\tPrec@5 75.000 (83.368)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [822/1141]\tLoss 0.3250 (1.8150)\tPrec@1 93.750 (52.054)\tPrec@5 96.875 (83.384)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [823/1141]\tLoss 0.6079 (1.8135)\tPrec@1 84.375 (52.093)\tPrec@5 93.750 (83.397)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [824/1141]\tLoss 0.3185 (1.8117)\tPrec@1 93.750 (52.144)\tPrec@5 96.875 (83.413)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [825/1141]\tLoss 2.2649 (1.8123)\tPrec@1 31.250 (52.119)\tPrec@5 81.250 (83.410)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [826/1141]\tLoss 1.7567 (1.8122)\tPrec@1 59.375 (52.127)\tPrec@5 81.250 (83.408)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [827/1141]\tLoss 2.1145 (1.8126)\tPrec@1 34.375 (52.106)\tPrec@5 81.250 (83.405)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [828/1141]\tLoss 1.9959 (1.8128)\tPrec@1 37.500 (52.088)\tPrec@5 84.375 (83.406)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [829/1141]\tLoss 1.4592 (1.8124)\tPrec@1 65.625 (52.105)\tPrec@5 84.375 (83.407)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [830/1141]\tLoss 1.7371 (1.8123)\tPrec@1 50.000 (52.102)\tPrec@5 87.500 (83.412)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [831/1141]\tLoss 1.8873 (1.8124)\tPrec@1 50.000 (52.100)\tPrec@5 87.500 (83.417)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [832/1141]\tLoss 2.0135 (1.8126)\tPrec@1 37.500 (52.082)\tPrec@5 87.500 (83.422)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [833/1141]\tLoss 1.2590 (1.8119)\tPrec@1 68.750 (52.102)\tPrec@5 93.750 (83.435)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [834/1141]\tLoss 2.5453 (1.8128)\tPrec@1 37.500 (52.085)\tPrec@5 68.750 (83.417)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [835/1141]\tLoss 2.0627 (1.8131)\tPrec@1 53.125 (52.086)\tPrec@5 68.750 (83.399)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [836/1141]\tLoss 1.4573 (1.8127)\tPrec@1 65.625 (52.102)\tPrec@5 78.125 (83.393)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [837/1141]\tLoss 1.6998 (1.8126)\tPrec@1 62.500 (52.114)\tPrec@5 81.250 (83.391)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [838/1141]\tLoss 1.1261 (1.8117)\tPrec@1 71.875 (52.138)\tPrec@5 93.750 (83.403)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [839/1141]\tLoss 1.2591 (1.8111)\tPrec@1 71.875 (52.161)\tPrec@5 84.375 (83.404)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [840/1141]\tLoss 1.9347 (1.8112)\tPrec@1 53.125 (52.163)\tPrec@5 78.125 (83.398)\n",
      "tensor(40.6250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [841/1141]\tLoss 1.6321 (1.8110)\tPrec@1 40.625 (52.149)\tPrec@5 90.625 (83.406)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [842/1141]\tLoss 1.8939 (1.8111)\tPrec@1 53.125 (52.150)\tPrec@5 78.125 (83.400)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [843/1141]\tLoss 2.8829 (1.8124)\tPrec@1 25.000 (52.118)\tPrec@5 68.750 (83.383)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [844/1141]\tLoss 2.9020 (1.8137)\tPrec@1 25.000 (52.086)\tPrec@5 75.000 (83.373)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [845/1141]\tLoss 2.5298 (1.8145)\tPrec@1 21.875 (52.050)\tPrec@5 68.750 (83.355)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [846/1141]\tLoss 3.4224 (1.8164)\tPrec@1 21.875 (52.014)\tPrec@5 56.250 (83.323)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [847/1141]\tLoss 2.5595 (1.8173)\tPrec@1 31.250 (51.990)\tPrec@5 68.750 (83.306)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [848/1141]\tLoss 2.5411 (1.8182)\tPrec@1 18.750 (51.951)\tPrec@5 78.125 (83.300)\n",
      "tensor(12.5000, device='cuda:0')\n",
      "Test: [849/1141]\tLoss 3.0644 (1.8196)\tPrec@1 12.500 (51.904)\tPrec@5 59.375 (83.272)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [850/1141]\tLoss 2.0535 (1.8199)\tPrec@1 34.375 (51.884)\tPrec@5 84.375 (83.273)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [851/1141]\tLoss 1.2905 (1.8193)\tPrec@1 62.500 (51.896)\tPrec@5 93.750 (83.286)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [852/1141]\tLoss 1.8824 (1.8193)\tPrec@1 43.750 (51.887)\tPrec@5 81.250 (83.283)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [853/1141]\tLoss 1.7597 (1.8193)\tPrec@1 56.250 (51.892)\tPrec@5 84.375 (83.285)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [854/1141]\tLoss 1.4448 (1.8188)\tPrec@1 62.500 (51.904)\tPrec@5 93.750 (83.297)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [855/1141]\tLoss 2.1430 (1.8192)\tPrec@1 31.250 (51.880)\tPrec@5 81.250 (83.294)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [856/1141]\tLoss 1.5651 (1.8189)\tPrec@1 68.750 (51.900)\tPrec@5 90.625 (83.303)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [857/1141]\tLoss 1.6176 (1.8187)\tPrec@1 59.375 (51.909)\tPrec@5 81.250 (83.301)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [858/1141]\tLoss 2.0247 (1.8189)\tPrec@1 37.500 (51.892)\tPrec@5 87.500 (83.305)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [859/1141]\tLoss 0.5958 (1.8175)\tPrec@1 81.250 (51.926)\tPrec@5 100.000 (83.325)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [860/1141]\tLoss 1.3368 (1.8169)\tPrec@1 71.875 (51.949)\tPrec@5 87.500 (83.330)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [861/1141]\tLoss 1.4099 (1.8165)\tPrec@1 81.250 (51.983)\tPrec@5 87.500 (83.335)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [862/1141]\tLoss 0.8041 (1.8153)\tPrec@1 84.375 (52.021)\tPrec@5 96.875 (83.350)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [863/1141]\tLoss 0.9517 (1.8143)\tPrec@1 75.000 (52.047)\tPrec@5 93.750 (83.362)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [864/1141]\tLoss 0.5910 (1.8129)\tPrec@1 90.625 (52.092)\tPrec@5 90.625 (83.371)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [865/1141]\tLoss 0.6110 (1.8115)\tPrec@1 81.250 (52.125)\tPrec@5 93.750 (83.383)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [866/1141]\tLoss 1.1961 (1.8108)\tPrec@1 71.875 (52.148)\tPrec@5 84.375 (83.384)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [867/1141]\tLoss 0.8530 (1.8097)\tPrec@1 81.250 (52.182)\tPrec@5 90.625 (83.392)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [868/1141]\tLoss 0.8154 (1.8085)\tPrec@1 81.250 (52.215)\tPrec@5 93.750 (83.404)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [869/1141]\tLoss 1.3865 (1.8081)\tPrec@1 75.000 (52.241)\tPrec@5 90.625 (83.412)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [870/1141]\tLoss 1.8414 (1.8081)\tPrec@1 59.375 (52.250)\tPrec@5 78.125 (83.406)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [871/1141]\tLoss 2.0356 (1.8084)\tPrec@1 53.125 (52.251)\tPrec@5 78.125 (83.400)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [872/1141]\tLoss 2.6402 (1.8093)\tPrec@1 18.750 (52.212)\tPrec@5 75.000 (83.391)\n",
      "tensor(21.8750, device='cuda:0')\n",
      "Test: [873/1141]\tLoss 2.6031 (1.8102)\tPrec@1 21.875 (52.177)\tPrec@5 87.500 (83.395)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [874/1141]\tLoss 2.5604 (1.8111)\tPrec@1 25.000 (52.146)\tPrec@5 84.375 (83.396)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [875/1141]\tLoss 1.8361 (1.8111)\tPrec@1 46.875 (52.140)\tPrec@5 78.125 (83.390)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [876/1141]\tLoss 1.9895 (1.8113)\tPrec@1 62.500 (52.152)\tPrec@5 71.875 (83.377)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [877/1141]\tLoss 1.5719 (1.8110)\tPrec@1 62.500 (52.164)\tPrec@5 81.250 (83.375)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [878/1141]\tLoss 2.4803 (1.8118)\tPrec@1 37.500 (52.147)\tPrec@5 65.625 (83.355)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [879/1141]\tLoss 2.2501 (1.8123)\tPrec@1 50.000 (52.145)\tPrec@5 71.875 (83.342)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [880/1141]\tLoss 2.3485 (1.8129)\tPrec@1 50.000 (52.142)\tPrec@5 62.500 (83.318)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [881/1141]\tLoss 2.9406 (1.8142)\tPrec@1 28.125 (52.115)\tPrec@5 65.625 (83.298)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [882/1141]\tLoss 3.0769 (1.8156)\tPrec@1 15.625 (52.074)\tPrec@5 68.750 (83.281)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [883/1141]\tLoss 2.7619 (1.8167)\tPrec@1 15.625 (52.033)\tPrec@5 68.750 (83.265)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [884/1141]\tLoss 2.5362 (1.8175)\tPrec@1 43.750 (52.023)\tPrec@5 75.000 (83.256)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [885/1141]\tLoss 2.9201 (1.8187)\tPrec@1 28.125 (51.996)\tPrec@5 65.625 (83.236)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [886/1141]\tLoss 2.3977 (1.8194)\tPrec@1 50.000 (51.994)\tPrec@5 81.250 (83.234)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [887/1141]\tLoss 2.3723 (1.8200)\tPrec@1 28.125 (51.967)\tPrec@5 75.000 (83.224)\n",
      "tensor(31.2500, device='cuda:0')\n",
      "Test: [888/1141]\tLoss 2.6965 (1.8210)\tPrec@1 31.250 (51.944)\tPrec@5 62.500 (83.201)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [889/1141]\tLoss 2.4988 (1.8218)\tPrec@1 28.125 (51.917)\tPrec@5 81.250 (83.199)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [890/1141]\tLoss 2.9249 (1.8230)\tPrec@1 25.000 (51.887)\tPrec@5 68.750 (83.183)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [891/1141]\tLoss 1.1622 (1.8223)\tPrec@1 65.625 (51.902)\tPrec@5 93.750 (83.194)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [892/1141]\tLoss 1.6940 (1.8221)\tPrec@1 56.250 (51.907)\tPrec@5 81.250 (83.192)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [893/1141]\tLoss 1.5963 (1.8219)\tPrec@1 62.500 (51.919)\tPrec@5 84.375 (83.194)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [894/1141]\tLoss 2.0413 (1.8221)\tPrec@1 53.125 (51.920)\tPrec@5 81.250 (83.191)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [895/1141]\tLoss 1.8799 (1.8222)\tPrec@1 62.500 (51.932)\tPrec@5 84.375 (83.193)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [896/1141]\tLoss 2.3951 (1.8228)\tPrec@1 34.375 (51.913)\tPrec@5 78.125 (83.187)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [897/1141]\tLoss 0.9415 (1.8218)\tPrec@1 75.000 (51.938)\tPrec@5 96.875 (83.202)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [898/1141]\tLoss 1.6229 (1.8216)\tPrec@1 53.125 (51.940)\tPrec@5 90.625 (83.211)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [899/1141]\tLoss 1.0737 (1.8208)\tPrec@1 75.000 (51.965)\tPrec@5 90.625 (83.219)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [900/1141]\tLoss 3.3587 (1.8225)\tPrec@1 9.375 (51.918)\tPrec@5 56.250 (83.189)\n",
      "tensor(3.1250, device='cuda:0')\n",
      "Test: [901/1141]\tLoss 3.2652 (1.8241)\tPrec@1 3.125 (51.864)\tPrec@5 65.625 (83.169)\n",
      "tensor(3.1250, device='cuda:0')\n",
      "Test: [902/1141]\tLoss 3.5559 (1.8260)\tPrec@1 3.125 (51.810)\tPrec@5 46.875 (83.129)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [903/1141]\tLoss 0.9302 (1.8250)\tPrec@1 75.000 (51.836)\tPrec@5 96.875 (83.144)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [904/1141]\tLoss 1.1090 (1.8242)\tPrec@1 68.750 (51.854)\tPrec@5 90.625 (83.153)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [905/1141]\tLoss 0.7055 (1.8230)\tPrec@1 93.750 (51.901)\tPrec@5 96.875 (83.168)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [906/1141]\tLoss 1.5747 (1.8227)\tPrec@1 59.375 (51.909)\tPrec@5 87.500 (83.173)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [907/1141]\tLoss 1.2630 (1.8221)\tPrec@1 62.500 (51.920)\tPrec@5 96.875 (83.188)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [908/1141]\tLoss 1.9901 (1.8223)\tPrec@1 40.625 (51.908)\tPrec@5 90.625 (83.196)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [909/1141]\tLoss 1.3518 (1.8218)\tPrec@1 59.375 (51.916)\tPrec@5 90.625 (83.204)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [910/1141]\tLoss 1.0445 (1.8209)\tPrec@1 81.250 (51.948)\tPrec@5 87.500 (83.209)\n",
      "tensor(75., device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [911/1141]\tLoss 1.0396 (1.8201)\tPrec@1 75.000 (51.974)\tPrec@5 93.750 (83.220)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [912/1141]\tLoss 1.0585 (1.8192)\tPrec@1 71.875 (51.995)\tPrec@5 93.750 (83.232)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [913/1141]\tLoss 2.1508 (1.8196)\tPrec@1 46.875 (51.990)\tPrec@5 81.250 (83.230)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [914/1141]\tLoss 1.8485 (1.8196)\tPrec@1 43.750 (51.981)\tPrec@5 81.250 (83.227)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [915/1141]\tLoss 1.5828 (1.8194)\tPrec@1 62.500 (51.992)\tPrec@5 81.250 (83.225)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [916/1141]\tLoss 0.9497 (1.8184)\tPrec@1 65.625 (52.007)\tPrec@5 100.000 (83.244)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [917/1141]\tLoss 1.2512 (1.8178)\tPrec@1 53.125 (52.008)\tPrec@5 90.625 (83.252)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [918/1141]\tLoss 1.4025 (1.8173)\tPrec@1 53.125 (52.010)\tPrec@5 90.625 (83.260)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [919/1141]\tLoss 0.8345 (1.8163)\tPrec@1 78.125 (52.038)\tPrec@5 93.750 (83.271)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [920/1141]\tLoss 1.1559 (1.8156)\tPrec@1 68.750 (52.056)\tPrec@5 90.625 (83.279)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [921/1141]\tLoss 1.0200 (1.8147)\tPrec@1 71.875 (52.078)\tPrec@5 90.625 (83.287)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [922/1141]\tLoss 1.3616 (1.8142)\tPrec@1 65.625 (52.092)\tPrec@5 84.375 (83.288)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [923/1141]\tLoss 0.6704 (1.8130)\tPrec@1 84.375 (52.127)\tPrec@5 90.625 (83.296)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [924/1141]\tLoss 0.4788 (1.8115)\tPrec@1 90.625 (52.169)\tPrec@5 96.875 (83.311)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [925/1141]\tLoss 2.0357 (1.8118)\tPrec@1 56.250 (52.173)\tPrec@5 65.625 (83.292)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [926/1141]\tLoss 2.0121 (1.8120)\tPrec@1 59.375 (52.181)\tPrec@5 75.000 (83.283)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [927/1141]\tLoss 1.0772 (1.8112)\tPrec@1 71.875 (52.202)\tPrec@5 87.500 (83.287)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [928/1141]\tLoss 2.6642 (1.8121)\tPrec@1 34.375 (52.183)\tPrec@5 75.000 (83.278)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [929/1141]\tLoss 2.6542 (1.8130)\tPrec@1 28.125 (52.157)\tPrec@5 68.750 (83.263)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [930/1141]\tLoss 2.9162 (1.8142)\tPrec@1 28.125 (52.131)\tPrec@5 68.750 (83.247)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [931/1141]\tLoss 1.8743 (1.8143)\tPrec@1 59.375 (52.139)\tPrec@5 81.250 (83.245)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [932/1141]\tLoss 1.2989 (1.8137)\tPrec@1 59.375 (52.147)\tPrec@5 90.625 (83.253)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [933/1141]\tLoss 1.2169 (1.8131)\tPrec@1 68.750 (52.165)\tPrec@5 90.625 (83.261)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [934/1141]\tLoss 2.0825 (1.8134)\tPrec@1 40.625 (52.152)\tPrec@5 81.250 (83.259)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [935/1141]\tLoss 2.3937 (1.8140)\tPrec@1 40.625 (52.140)\tPrec@5 78.125 (83.253)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [936/1141]\tLoss 2.3885 (1.8146)\tPrec@1 43.750 (52.131)\tPrec@5 78.125 (83.248)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [937/1141]\tLoss 1.2685 (1.8140)\tPrec@1 59.375 (52.139)\tPrec@5 93.750 (83.259)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [938/1141]\tLoss 1.0693 (1.8132)\tPrec@1 71.875 (52.160)\tPrec@5 90.625 (83.267)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [939/1141]\tLoss 1.2914 (1.8127)\tPrec@1 71.875 (52.181)\tPrec@5 87.500 (83.271)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [940/1141]\tLoss 1.5445 (1.8124)\tPrec@1 59.375 (52.188)\tPrec@5 81.250 (83.269)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [941/1141]\tLoss 1.5500 (1.8121)\tPrec@1 59.375 (52.196)\tPrec@5 90.625 (83.277)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [942/1141]\tLoss 1.3559 (1.8116)\tPrec@1 68.750 (52.214)\tPrec@5 90.625 (83.285)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [943/1141]\tLoss 1.9010 (1.8117)\tPrec@1 53.125 (52.215)\tPrec@5 81.250 (83.283)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [944/1141]\tLoss 1.8788 (1.8118)\tPrec@1 40.625 (52.202)\tPrec@5 84.375 (83.284)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [945/1141]\tLoss 2.0579 (1.8120)\tPrec@1 28.125 (52.177)\tPrec@5 75.000 (83.275)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [946/1141]\tLoss 1.8767 (1.8121)\tPrec@1 50.000 (52.175)\tPrec@5 84.375 (83.276)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [947/1141]\tLoss 1.7301 (1.8120)\tPrec@1 34.375 (52.156)\tPrec@5 93.750 (83.287)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [948/1141]\tLoss 1.1205 (1.8113)\tPrec@1 56.250 (52.160)\tPrec@5 96.875 (83.301)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [949/1141]\tLoss 1.4557 (1.8109)\tPrec@1 56.250 (52.164)\tPrec@5 90.625 (83.309)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [950/1141]\tLoss 1.8792 (1.8110)\tPrec@1 53.125 (52.165)\tPrec@5 87.500 (83.314)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [951/1141]\tLoss 1.5117 (1.8107)\tPrec@1 56.250 (52.170)\tPrec@5 90.625 (83.321)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [952/1141]\tLoss 1.3139 (1.8101)\tPrec@1 56.250 (52.174)\tPrec@5 96.875 (83.336)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [953/1141]\tLoss 1.0718 (1.8094)\tPrec@1 68.750 (52.191)\tPrec@5 96.875 (83.350)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [954/1141]\tLoss 0.9322 (1.8085)\tPrec@1 75.000 (52.215)\tPrec@5 96.875 (83.364)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [955/1141]\tLoss 1.0953 (1.8077)\tPrec@1 62.500 (52.226)\tPrec@5 96.875 (83.378)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [956/1141]\tLoss 1.5169 (1.8074)\tPrec@1 56.250 (52.230)\tPrec@5 87.500 (83.382)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [957/1141]\tLoss 2.0912 (1.8077)\tPrec@1 37.500 (52.215)\tPrec@5 78.125 (83.377)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [958/1141]\tLoss 1.5182 (1.8074)\tPrec@1 62.500 (52.226)\tPrec@5 90.625 (83.384)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [959/1141]\tLoss 0.7836 (1.8063)\tPrec@1 81.250 (52.256)\tPrec@5 100.000 (83.402)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [960/1141]\tLoss 1.4584 (1.8060)\tPrec@1 59.375 (52.263)\tPrec@5 90.625 (83.409)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [961/1141]\tLoss 1.6522 (1.8058)\tPrec@1 68.750 (52.280)\tPrec@5 84.375 (83.410)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [962/1141]\tLoss 2.0657 (1.8061)\tPrec@1 46.875 (52.275)\tPrec@5 81.250 (83.408)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [963/1141]\tLoss 2.3925 (1.8067)\tPrec@1 40.625 (52.263)\tPrec@5 75.000 (83.399)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [964/1141]\tLoss 1.5245 (1.8064)\tPrec@1 56.250 (52.267)\tPrec@5 87.500 (83.404)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [965/1141]\tLoss 1.9259 (1.8065)\tPrec@1 43.750 (52.258)\tPrec@5 84.375 (83.405)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [966/1141]\tLoss 1.7684 (1.8065)\tPrec@1 50.000 (52.256)\tPrec@5 87.500 (83.409)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [967/1141]\tLoss 1.5553 (1.8062)\tPrec@1 46.875 (52.250)\tPrec@5 93.750 (83.419)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [968/1141]\tLoss 1.1775 (1.8056)\tPrec@1 62.500 (52.261)\tPrec@5 93.750 (83.430)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [969/1141]\tLoss 1.3735 (1.8051)\tPrec@1 71.875 (52.281)\tPrec@5 90.625 (83.438)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [970/1141]\tLoss 0.7278 (1.8040)\tPrec@1 81.250 (52.311)\tPrec@5 100.000 (83.455)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [971/1141]\tLoss 1.1073 (1.8033)\tPrec@1 65.625 (52.324)\tPrec@5 93.750 (83.465)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [972/1141]\tLoss 1.4598 (1.8029)\tPrec@1 59.375 (52.332)\tPrec@5 84.375 (83.466)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [973/1141]\tLoss 1.7297 (1.8029)\tPrec@1 53.125 (52.333)\tPrec@5 84.375 (83.467)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [974/1141]\tLoss 1.0716 (1.8021)\tPrec@1 75.000 (52.356)\tPrec@5 93.750 (83.478)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [975/1141]\tLoss 0.8435 (1.8011)\tPrec@1 59.375 (52.363)\tPrec@5 96.875 (83.491)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [976/1141]\tLoss 0.8806 (1.8002)\tPrec@1 78.125 (52.389)\tPrec@5 96.875 (83.505)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [977/1141]\tLoss 0.6924 (1.7991)\tPrec@1 75.000 (52.412)\tPrec@5 96.875 (83.519)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [978/1141]\tLoss 1.7737 (1.7990)\tPrec@1 15.625 (52.375)\tPrec@5 93.750 (83.529)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [979/1141]\tLoss 1.6414 (1.7989)\tPrec@1 15.625 (52.337)\tPrec@5 90.625 (83.536)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [980/1141]\tLoss 1.3922 (1.7985)\tPrec@1 25.000 (52.310)\tPrec@5 96.875 (83.550)\n",
      "tensor(59.3750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [981/1141]\tLoss 1.3755 (1.7980)\tPrec@1 59.375 (52.317)\tPrec@5 96.875 (83.564)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [982/1141]\tLoss 1.1193 (1.7973)\tPrec@1 71.875 (52.337)\tPrec@5 96.875 (83.577)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [983/1141]\tLoss 1.1172 (1.7967)\tPrec@1 65.625 (52.350)\tPrec@5 93.750 (83.587)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [984/1141]\tLoss 1.7227 (1.7966)\tPrec@1 56.250 (52.354)\tPrec@5 90.625 (83.595)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [985/1141]\tLoss 1.8696 (1.7967)\tPrec@1 43.750 (52.345)\tPrec@5 93.750 (83.605)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [986/1141]\tLoss 2.1907 (1.7971)\tPrec@1 40.625 (52.333)\tPrec@5 75.000 (83.596)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [987/1141]\tLoss 0.7176 (1.7960)\tPrec@1 81.250 (52.363)\tPrec@5 96.875 (83.610)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [988/1141]\tLoss 1.1261 (1.7953)\tPrec@1 68.750 (52.379)\tPrec@5 90.625 (83.617)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [989/1141]\tLoss 1.2548 (1.7947)\tPrec@1 71.875 (52.399)\tPrec@5 87.500 (83.621)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [990/1141]\tLoss 1.0474 (1.7940)\tPrec@1 62.500 (52.409)\tPrec@5 93.750 (83.631)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [991/1141]\tLoss 1.6049 (1.7938)\tPrec@1 53.125 (52.410)\tPrec@5 93.750 (83.641)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [992/1141]\tLoss 2.1315 (1.7941)\tPrec@1 34.375 (52.392)\tPrec@5 81.250 (83.639)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [993/1141]\tLoss 2.7620 (1.7951)\tPrec@1 37.500 (52.377)\tPrec@5 75.000 (83.630)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [994/1141]\tLoss 2.2427 (1.7956)\tPrec@1 28.125 (52.352)\tPrec@5 87.500 (83.634)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [995/1141]\tLoss 2.6770 (1.7964)\tPrec@1 28.125 (52.328)\tPrec@5 78.125 (83.628)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [996/1141]\tLoss 2.7299 (1.7974)\tPrec@1 53.125 (52.329)\tPrec@5 68.750 (83.613)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [997/1141]\tLoss 1.7371 (1.7973)\tPrec@1 50.000 (52.327)\tPrec@5 90.625 (83.620)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [998/1141]\tLoss 1.1537 (1.7967)\tPrec@1 65.625 (52.340)\tPrec@5 90.625 (83.627)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [999/1141]\tLoss 1.8730 (1.7967)\tPrec@1 56.250 (52.344)\tPrec@5 84.375 (83.628)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1000/1141]\tLoss 1.3381 (1.7963)\tPrec@1 62.500 (52.354)\tPrec@5 90.625 (83.635)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1001/1141]\tLoss 1.1570 (1.7957)\tPrec@1 75.000 (52.376)\tPrec@5 87.500 (83.639)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [1002/1141]\tLoss 1.7473 (1.7956)\tPrec@1 53.125 (52.377)\tPrec@5 90.625 (83.646)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1003/1141]\tLoss 2.2961 (1.7961)\tPrec@1 46.875 (52.372)\tPrec@5 81.250 (83.644)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [1004/1141]\tLoss 1.7716 (1.7961)\tPrec@1 43.750 (52.363)\tPrec@5 81.250 (83.641)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [1005/1141]\tLoss 2.0083 (1.7963)\tPrec@1 37.500 (52.348)\tPrec@5 81.250 (83.639)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1006/1141]\tLoss 2.2530 (1.7967)\tPrec@1 46.875 (52.343)\tPrec@5 68.750 (83.624)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [1007/1141]\tLoss 2.9903 (1.7979)\tPrec@1 28.125 (52.319)\tPrec@5 59.375 (83.600)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [1008/1141]\tLoss 1.7469 (1.7979)\tPrec@1 53.125 (52.320)\tPrec@5 78.125 (83.595)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [1009/1141]\tLoss 1.8465 (1.7979)\tPrec@1 50.000 (52.317)\tPrec@5 81.250 (83.592)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1010/1141]\tLoss 2.2645 (1.7984)\tPrec@1 46.875 (52.312)\tPrec@5 78.125 (83.587)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1011/1141]\tLoss 2.0750 (1.7987)\tPrec@1 46.875 (52.307)\tPrec@5 78.125 (83.581)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1012/1141]\tLoss 1.9216 (1.7988)\tPrec@1 46.875 (52.301)\tPrec@5 75.000 (83.573)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [1013/1141]\tLoss 1.2078 (1.7982)\tPrec@1 81.250 (52.330)\tPrec@5 90.625 (83.580)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1014/1141]\tLoss 1.8803 (1.7983)\tPrec@1 59.375 (52.337)\tPrec@5 84.375 (83.581)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1015/1141]\tLoss 0.9419 (1.7974)\tPrec@1 71.875 (52.356)\tPrec@5 93.750 (83.591)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1016/1141]\tLoss 0.9800 (1.7966)\tPrec@1 75.000 (52.378)\tPrec@5 93.750 (83.601)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1017/1141]\tLoss 0.8453 (1.7957)\tPrec@1 71.875 (52.397)\tPrec@5 96.875 (83.614)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1018/1141]\tLoss 0.9455 (1.7949)\tPrec@1 71.875 (52.417)\tPrec@5 96.875 (83.627)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1019/1141]\tLoss 0.8901 (1.7940)\tPrec@1 75.000 (52.439)\tPrec@5 100.000 (83.643)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [1020/1141]\tLoss 0.6951 (1.7929)\tPrec@1 84.375 (52.470)\tPrec@5 93.750 (83.653)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [1021/1141]\tLoss 0.6814 (1.7918)\tPrec@1 81.250 (52.498)\tPrec@5 100.000 (83.669)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [1022/1141]\tLoss 1.3037 (1.7913)\tPrec@1 56.250 (52.502)\tPrec@5 96.875 (83.682)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1023/1141]\tLoss 0.8803 (1.7904)\tPrec@1 71.875 (52.521)\tPrec@5 96.875 (83.694)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [1024/1141]\tLoss 1.1979 (1.7899)\tPrec@1 78.125 (52.546)\tPrec@5 93.750 (83.704)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [1025/1141]\tLoss 1.6182 (1.7897)\tPrec@1 43.750 (52.537)\tPrec@5 90.625 (83.711)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [1026/1141]\tLoss 1.6446 (1.7896)\tPrec@1 43.750 (52.529)\tPrec@5 93.750 (83.721)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1027/1141]\tLoss 1.4260 (1.7892)\tPrec@1 62.500 (52.538)\tPrec@5 87.500 (83.724)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [1028/1141]\tLoss 2.3867 (1.7898)\tPrec@1 40.625 (52.527)\tPrec@5 81.250 (83.722)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1029/1141]\tLoss 1.1670 (1.7892)\tPrec@1 71.875 (52.546)\tPrec@5 93.750 (83.732)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1030/1141]\tLoss 1.9608 (1.7893)\tPrec@1 46.875 (52.540)\tPrec@5 78.125 (83.726)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [1031/1141]\tLoss 2.2536 (1.7898)\tPrec@1 40.625 (52.528)\tPrec@5 81.250 (83.724)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [1032/1141]\tLoss 1.7594 (1.7898)\tPrec@1 50.000 (52.526)\tPrec@5 81.250 (83.722)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1033/1141]\tLoss 1.8467 (1.7898)\tPrec@1 46.875 (52.521)\tPrec@5 81.250 (83.719)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1034/1141]\tLoss 1.6214 (1.7897)\tPrec@1 65.625 (52.533)\tPrec@5 87.500 (83.723)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [1035/1141]\tLoss 0.8813 (1.7888)\tPrec@1 78.125 (52.558)\tPrec@5 93.750 (83.733)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [1036/1141]\tLoss 0.6162 (1.7877)\tPrec@1 81.250 (52.586)\tPrec@5 96.875 (83.745)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [1037/1141]\tLoss 1.1334 (1.7870)\tPrec@1 78.125 (52.610)\tPrec@5 90.625 (83.752)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1038/1141]\tLoss 1.4490 (1.7867)\tPrec@1 65.625 (52.623)\tPrec@5 87.500 (83.755)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1039/1141]\tLoss 1.5747 (1.7865)\tPrec@1 59.375 (52.629)\tPrec@5 81.250 (83.753)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1040/1141]\tLoss 1.5983 (1.7863)\tPrec@1 59.375 (52.636)\tPrec@5 87.500 (83.757)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1041/1141]\tLoss 1.2796 (1.7858)\tPrec@1 68.750 (52.651)\tPrec@5 87.500 (83.760)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1042/1141]\tLoss 1.3366 (1.7854)\tPrec@1 68.750 (52.667)\tPrec@5 90.625 (83.767)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1043/1141]\tLoss 1.8504 (1.7855)\tPrec@1 46.875 (52.661)\tPrec@5 78.125 (83.761)\n",
      "tensor(25., device='cuda:0')\n",
      "Test: [1044/1141]\tLoss 2.4591 (1.7861)\tPrec@1 25.000 (52.635)\tPrec@5 84.375 (83.762)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [1045/1141]\tLoss 2.5596 (1.7868)\tPrec@1 40.625 (52.623)\tPrec@5 81.250 (83.760)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [1046/1141]\tLoss 2.1321 (1.7872)\tPrec@1 37.500 (52.609)\tPrec@5 81.250 (83.757)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1047/1141]\tLoss 2.0628 (1.7874)\tPrec@1 46.875 (52.603)\tPrec@5 87.500 (83.761)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [1048/1141]\tLoss 2.3751 (1.7880)\tPrec@1 40.625 (52.592)\tPrec@5 71.875 (83.749)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1049/1141]\tLoss 2.4100 (1.7886)\tPrec@1 46.875 (52.586)\tPrec@5 71.875 (83.738)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [1050/1141]\tLoss 0.9103 (1.7878)\tPrec@1 78.125 (52.611)\tPrec@5 87.500 (83.742)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1051/1141]\tLoss 1.2031 (1.7872)\tPrec@1 68.750 (52.626)\tPrec@5 96.875 (83.754)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1052/1141]\tLoss 0.9278 (1.7864)\tPrec@1 62.500 (52.635)\tPrec@5 96.875 (83.767)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [1053/1141]\tLoss 1.6924 (1.7863)\tPrec@1 53.125 (52.636)\tPrec@5 87.500 (83.770)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1054/1141]\tLoss 0.8975 (1.7854)\tPrec@1 68.750 (52.651)\tPrec@5 93.750 (83.780)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1055/1141]\tLoss 0.8242 (1.7845)\tPrec@1 65.625 (52.663)\tPrec@5 100.000 (83.795)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1056/1141]\tLoss 1.4544 (1.7842)\tPrec@1 62.500 (52.673)\tPrec@5 81.250 (83.793)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1057/1141]\tLoss 1.8555 (1.7843)\tPrec@1 46.875 (52.667)\tPrec@5 81.250 (83.790)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [1058/1141]\tLoss 1.9664 (1.7845)\tPrec@1 56.250 (52.671)\tPrec@5 75.000 (83.782)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1059/1141]\tLoss 1.2125 (1.7839)\tPrec@1 71.875 (52.689)\tPrec@5 87.500 (83.785)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [1060/1141]\tLoss 1.7323 (1.7839)\tPrec@1 56.250 (52.692)\tPrec@5 87.500 (83.789)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [1061/1141]\tLoss 1.8487 (1.7839)\tPrec@1 50.000 (52.689)\tPrec@5 84.375 (83.789)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1062/1141]\tLoss 1.8249 (1.7840)\tPrec@1 62.500 (52.699)\tPrec@5 84.375 (83.790)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1063/1141]\tLoss 1.4933 (1.7837)\tPrec@1 59.375 (52.705)\tPrec@5 90.625 (83.796)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [1064/1141]\tLoss 1.4866 (1.7834)\tPrec@1 56.250 (52.708)\tPrec@5 84.375 (83.797)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1065/1141]\tLoss 1.2104 (1.7829)\tPrec@1 62.500 (52.718)\tPrec@5 93.750 (83.806)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [1066/1141]\tLoss 1.8262 (1.7829)\tPrec@1 53.125 (52.718)\tPrec@5 84.375 (83.807)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1067/1141]\tLoss 1.8511 (1.7830)\tPrec@1 46.875 (52.712)\tPrec@5 81.250 (83.804)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1068/1141]\tLoss 1.6790 (1.7829)\tPrec@1 62.500 (52.722)\tPrec@5 84.375 (83.805)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [1069/1141]\tLoss 0.3073 (1.7815)\tPrec@1 87.500 (52.754)\tPrec@5 100.000 (83.820)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [1070/1141]\tLoss 0.5429 (1.7804)\tPrec@1 87.500 (52.787)\tPrec@5 93.750 (83.829)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1071/1141]\tLoss 0.8514 (1.7795)\tPrec@1 71.875 (52.804)\tPrec@5 93.750 (83.839)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1072/1141]\tLoss 1.2133 (1.7790)\tPrec@1 62.500 (52.813)\tPrec@5 93.750 (83.848)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1073/1141]\tLoss 1.5790 (1.7788)\tPrec@1 59.375 (52.819)\tPrec@5 87.500 (83.851)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1074/1141]\tLoss 1.2448 (1.7783)\tPrec@1 62.500 (52.828)\tPrec@5 87.500 (83.855)\n",
      "tensor(9.3750, device='cuda:0')\n",
      "Test: [1075/1141]\tLoss 3.3328 (1.7797)\tPrec@1 9.375 (52.788)\tPrec@5 65.625 (83.838)\n",
      "tensor(6.2500, device='cuda:0')\n",
      "Test: [1076/1141]\tLoss 3.3245 (1.7812)\tPrec@1 6.250 (52.745)\tPrec@5 71.875 (83.827)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [1077/1141]\tLoss 2.7129 (1.7820)\tPrec@1 15.625 (52.710)\tPrec@5 62.500 (83.807)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [1078/1141]\tLoss 2.8869 (1.7830)\tPrec@1 28.125 (52.688)\tPrec@5 71.875 (83.796)\n",
      "tensor(18.7500, device='cuda:0')\n",
      "Test: [1079/1141]\tLoss 2.5245 (1.7837)\tPrec@1 18.750 (52.656)\tPrec@5 75.000 (83.788)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [1080/1141]\tLoss 2.2532 (1.7842)\tPrec@1 37.500 (52.642)\tPrec@5 84.375 (83.788)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1081/1141]\tLoss 1.0502 (1.7835)\tPrec@1 68.750 (52.657)\tPrec@5 93.750 (83.797)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1082/1141]\tLoss 1.2117 (1.7830)\tPrec@1 75.000 (52.678)\tPrec@5 90.625 (83.804)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [1083/1141]\tLoss 0.5477 (1.7818)\tPrec@1 90.625 (52.713)\tPrec@5 96.875 (83.816)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1084/1141]\tLoss 1.3479 (1.7814)\tPrec@1 65.625 (52.725)\tPrec@5 93.750 (83.825)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1085/1141]\tLoss 1.5900 (1.7812)\tPrec@1 65.625 (52.737)\tPrec@5 87.500 (83.828)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1086/1141]\tLoss 1.4188 (1.7809)\tPrec@1 75.000 (52.757)\tPrec@5 87.500 (83.832)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1087/1141]\tLoss 1.4799 (1.7806)\tPrec@1 62.500 (52.766)\tPrec@5 78.125 (83.826)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1088/1141]\tLoss 1.6867 (1.7806)\tPrec@1 65.625 (52.778)\tPrec@5 75.000 (83.818)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1089/1141]\tLoss 1.8610 (1.7806)\tPrec@1 59.375 (52.784)\tPrec@5 75.000 (83.810)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [1090/1141]\tLoss 1.9919 (1.7808)\tPrec@1 50.000 (52.781)\tPrec@5 75.000 (83.802)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1091/1141]\tLoss 1.2916 (1.7804)\tPrec@1 71.875 (52.799)\tPrec@5 81.250 (83.800)\n",
      "tensor(50., device='cuda:0')\n",
      "Test: [1092/1141]\tLoss 1.7431 (1.7803)\tPrec@1 50.000 (52.796)\tPrec@5 84.375 (83.800)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [1093/1141]\tLoss 0.8929 (1.7795)\tPrec@1 78.125 (52.819)\tPrec@5 90.625 (83.807)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1094/1141]\tLoss 0.9624 (1.7788)\tPrec@1 71.875 (52.837)\tPrec@5 90.625 (83.813)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [1095/1141]\tLoss 0.9997 (1.7781)\tPrec@1 78.125 (52.860)\tPrec@5 87.500 (83.816)\n",
      "tensor(78.1250, device='cuda:0')\n",
      "Test: [1096/1141]\tLoss 0.9620 (1.7773)\tPrec@1 78.125 (52.883)\tPrec@5 87.500 (83.820)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [1097/1141]\tLoss 0.5739 (1.7762)\tPrec@1 87.500 (52.914)\tPrec@5 96.875 (83.831)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [1098/1141]\tLoss 0.8962 (1.7754)\tPrec@1 84.375 (52.943)\tPrec@5 90.625 (83.838)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [1099/1141]\tLoss 0.5366 (1.7743)\tPrec@1 84.375 (52.972)\tPrec@5 100.000 (83.852)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [1100/1141]\tLoss 2.1101 (1.7746)\tPrec@1 37.500 (52.958)\tPrec@5 78.125 (83.847)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1101/1141]\tLoss 1.4947 (1.7744)\tPrec@1 59.375 (52.963)\tPrec@5 84.375 (83.848)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1102/1141]\tLoss 1.5390 (1.7741)\tPrec@1 62.500 (52.972)\tPrec@5 81.250 (83.845)\n",
      "tensor(46.8750, device='cuda:0')\n",
      "Test: [1103/1141]\tLoss 1.6550 (1.7740)\tPrec@1 46.875 (52.966)\tPrec@5 93.750 (83.854)\n",
      "tensor(43.7500, device='cuda:0')\n",
      "Test: [1104/1141]\tLoss 1.9393 (1.7742)\tPrec@1 43.750 (52.958)\tPrec@5 90.625 (83.860)\n",
      "tensor(53.1250, device='cuda:0')\n",
      "Test: [1105/1141]\tLoss 2.1397 (1.7745)\tPrec@1 53.125 (52.958)\tPrec@5 87.500 (83.864)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1106/1141]\tLoss 1.0203 (1.7738)\tPrec@1 68.750 (52.973)\tPrec@5 90.625 (83.870)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1107/1141]\tLoss 1.2020 (1.7733)\tPrec@1 71.875 (52.990)\tPrec@5 84.375 (83.870)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1108/1141]\tLoss 1.0384 (1.7727)\tPrec@1 75.000 (53.009)\tPrec@5 87.500 (83.873)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [1109/1141]\tLoss 0.5308 (1.7715)\tPrec@1 87.500 (53.041)\tPrec@5 100.000 (83.888)\n",
      "tensor(81.2500, device='cuda:0')\n",
      "Test: [1110/1141]\tLoss 1.0524 (1.7709)\tPrec@1 81.250 (53.066)\tPrec@5 93.750 (83.897)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1111/1141]\tLoss 1.1016 (1.7703)\tPrec@1 75.000 (53.086)\tPrec@5 90.625 (83.903)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1112/1141]\tLoss 1.5596 (1.7701)\tPrec@1 65.625 (53.097)\tPrec@5 87.500 (83.906)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [1113/1141]\tLoss 2.5564 (1.7708)\tPrec@1 37.500 (53.083)\tPrec@5 62.500 (83.887)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1114/1141]\tLoss 1.4855 (1.7705)\tPrec@1 62.500 (53.091)\tPrec@5 84.375 (83.887)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1115/1141]\tLoss 1.6398 (1.7704)\tPrec@1 59.375 (53.097)\tPrec@5 81.250 (83.885)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1116/1141]\tLoss 0.9801 (1.7697)\tPrec@1 75.000 (53.117)\tPrec@5 100.000 (83.899)\n",
      "tensor(56.2500, device='cuda:0')\n",
      "Test: [1117/1141]\tLoss 1.5597 (1.7695)\tPrec@1 56.250 (53.119)\tPrec@5 87.500 (83.903)\n",
      "tensor(71.8750, device='cuda:0')\n",
      "Test: [1118/1141]\tLoss 1.0691 (1.7689)\tPrec@1 71.875 (53.136)\tPrec@5 93.750 (83.911)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1119/1141]\tLoss 1.1598 (1.7684)\tPrec@1 65.625 (53.147)\tPrec@5 90.625 (83.917)\n",
      "tensor(62.5000, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [1120/1141]\tLoss 1.1629 (1.7678)\tPrec@1 62.500 (53.156)\tPrec@5 90.625 (83.923)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1121/1141]\tLoss 1.0662 (1.7672)\tPrec@1 65.625 (53.167)\tPrec@5 93.750 (83.932)\n",
      "tensor(75., device='cuda:0')\n",
      "Test: [1122/1141]\tLoss 1.2025 (1.7667)\tPrec@1 75.000 (53.186)\tPrec@5 90.625 (83.938)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1123/1141]\tLoss 1.3655 (1.7663)\tPrec@1 59.375 (53.192)\tPrec@5 90.625 (83.944)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1124/1141]\tLoss 0.9957 (1.7657)\tPrec@1 68.750 (53.206)\tPrec@5 93.750 (83.953)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [1125/1141]\tLoss 0.2613 (1.7643)\tPrec@1 93.750 (53.242)\tPrec@5 93.750 (83.961)\n",
      "tensor(87.5000, device='cuda:0')\n",
      "Test: [1126/1141]\tLoss 0.6553 (1.7633)\tPrec@1 87.500 (53.272)\tPrec@5 100.000 (83.976)\n",
      "tensor(90.6250, device='cuda:0')\n",
      "Test: [1127/1141]\tLoss 0.2562 (1.7620)\tPrec@1 90.625 (53.305)\tPrec@5 100.000 (83.990)\n",
      "tensor(93.7500, device='cuda:0')\n",
      "Test: [1128/1141]\tLoss 0.3770 (1.7608)\tPrec@1 93.750 (53.341)\tPrec@5 93.750 (83.999)\n",
      "tensor(96.8750, device='cuda:0')\n",
      "Test: [1129/1141]\tLoss 0.3473 (1.7595)\tPrec@1 96.875 (53.379)\tPrec@5 96.875 (84.010)\n",
      "tensor(84.3750, device='cuda:0')\n",
      "Test: [1130/1141]\tLoss 0.5776 (1.7585)\tPrec@1 84.375 (53.407)\tPrec@5 96.875 (84.021)\n",
      "tensor(37.5000, device='cuda:0')\n",
      "Test: [1131/1141]\tLoss 2.4746 (1.7591)\tPrec@1 37.500 (53.393)\tPrec@5 68.750 (84.008)\n",
      "tensor(15.6250, device='cuda:0')\n",
      "Test: [1132/1141]\tLoss 3.3145 (1.7605)\tPrec@1 15.625 (53.359)\tPrec@5 53.125 (83.981)\n",
      "tensor(28.1250, device='cuda:0')\n",
      "Test: [1133/1141]\tLoss 2.8203 (1.7614)\tPrec@1 28.125 (53.337)\tPrec@5 75.000 (83.973)\n",
      "tensor(34.3750, device='cuda:0')\n",
      "Test: [1134/1141]\tLoss 2.2204 (1.7618)\tPrec@1 34.375 (53.320)\tPrec@5 81.250 (83.970)\n",
      "tensor(40.6250, device='cuda:0')\n",
      "Test: [1135/1141]\tLoss 1.5794 (1.7617)\tPrec@1 40.625 (53.309)\tPrec@5 96.875 (83.982)\n",
      "tensor(59.3750, device='cuda:0')\n",
      "Test: [1136/1141]\tLoss 1.7412 (1.7616)\tPrec@1 59.375 (53.315)\tPrec@5 87.500 (83.985)\n",
      "tensor(62.5000, device='cuda:0')\n",
      "Test: [1137/1141]\tLoss 1.2006 (1.7611)\tPrec@1 62.500 (53.323)\tPrec@5 93.750 (83.993)\n",
      "tensor(65.6250, device='cuda:0')\n",
      "Test: [1138/1141]\tLoss 1.2300 (1.7607)\tPrec@1 65.625 (53.334)\tPrec@5 90.625 (83.999)\n",
      "tensor(68.7500, device='cuda:0')\n",
      "Test: [1139/1141]\tLoss 1.5615 (1.7605)\tPrec@1 68.750 (53.347)\tPrec@5 87.500 (84.002)\n",
      "tensor(70., device='cuda:0')\n",
      "Test: [1140/1141]\tLoss 1.3354 (1.7603)\tPrec@1 70.000 (53.356)\tPrec@5 90.000 (84.005)\n",
      " * Prec@1 53.356 Prec@5 84.005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_freq = 1\n",
    "# batch_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for i, (image_input, target) in enumerate(val_loader):\n",
    "    #image_input = image_input.to('cuda:0')\n",
    "    image_input = image_input.cuda()\n",
    "    target = target.cuda()\n",
    "    image_input_var = torch.autograd.Variable(image_input)\n",
    "    target_var = torch.autograd.Variable(target)\n",
    "\n",
    "    # compute output\n",
    "    output = model(image_input_var)\n",
    "    loss = criterion(output, target_var)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "    print(prec1)\n",
    "    losses.update(loss.data, image_input.size(0))\n",
    "    top1.update(prec1, image_input.size(0))\n",
    "    top5.update(prec5, image_input.size(0))\n",
    "\n",
    "#     # measure elapsed time\n",
    "#     batch_time.update(time.time() - end)\n",
    "#     end = time.time()\n",
    "\n",
    "    if (i % print_freq == 0):\n",
    "        print('Test: [{0}/{1}]\\t'\n",
    "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "            'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "            'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "            i, len(val_loader),  loss=losses,\n",
    "            top1=top1, top5=top5))\n",
    "\n",
    "print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Bottom(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ResNet50Bottom, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "res50_conv = ResNet50Bottom(model)\n",
    "\n",
    "outputs = res50_conv(image_input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(image_input_var.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2048, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
